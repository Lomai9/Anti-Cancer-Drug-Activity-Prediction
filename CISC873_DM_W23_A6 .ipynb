{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úîÔ∏è Problem Formulation:\n",
        "**The problem: ‚ùé**\n",
        "\n",
        "Anticancer activity prediction, where each chemical compound is represented as a graph, with atoms representing nodes and bonds as edges. A chemical compound is positive against non-small cell lung cancer, or negative otherwise. \n",
        "\n",
        "**What is the input? ‚è©**\n",
        "\n",
        "there are a train set and test set, 2 input features: nodes and edges between these nodes.\n",
        "\n",
        "**What is the output? ‚è™**\n",
        "\n",
        "Predict chemical compound is effective or Not.\n",
        "\n",
        "**What data mining function is required? ü§î**\n",
        "\n",
        "-Classification.\n",
        "-predection.\n",
        "-tokenization.\n",
        "\n",
        "**What could be the challenges? ‚õè**\n",
        "\n",
        "\n",
        "*   the train and test data are SDF file.\n",
        "\n",
        "*   Find the best way to train this data and get the best accuracy.\n",
        "\n",
        "*   Handle with data imbalance.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**What is the impact? üòÄ**\n",
        "\n",
        "The resolution of this medical issue will advance medicine, particularly in the treatment of lung cancer, by leading medical professionals to seek out the most effective treatments.\n",
        "\n",
        "**What is an ideal solution?**‚úä\n",
        "\n",
        "The Sixth trail when using GGNN after Resampleing.  \n",
        "GGNN can achieve better performance and accuracy than other GNN models or traditional machine learning methods for anti-cancer activity prediction.\n",
        "This Trail Get Score on Kaggle (0.85219)\n",
        "\n"
      ],
      "metadata": {
        "id": "fuc4TBY7w3-Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experimental protocol üíª\n",
        "-Read SDF format data (structured-data format)\n",
        "\n",
        "-read dataset from SDF file\n",
        "\n",
        "-Spilt train set to train validation set\n",
        "\n",
        "-Visualizing/Inspecting a Sample\n",
        "- Preprocessing:\n",
        "*   Toknization.\n",
        "\n",
        "-building models (the First five trail) without UP sampling We using:\n",
        "\n",
        "\n",
        "1.   GAN\n",
        "2.   RGCN\n",
        "3.   RGAT\n",
        "4.   RGIN\n",
        "5.   GGNN\n",
        "6.   Using Conv2d layer. (Multi-objective learning (multi-task))\n",
        "7.   Transfer learning (VGG model) (Multi-modality learning with Multi-objective learning)\n",
        "-Model Training\n",
        "-Predition\n",
        "-Create Submit file and check the score of each model on kaggle."
      ],
      "metadata": {
        "id": "vP8YmIznxfnj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tHAKVoBT0RV"
      },
      "source": [
        "## Read SDF format data (structured-data format) üîÄ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgT7rco6T0RX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def read_sdf(file):\n",
        "    with open(file, 'r') as rf:\n",
        "        content = rf.read()\n",
        "    samples = content.split('$$$$')\n",
        "    \n",
        "    def parse_sample(s):\n",
        "        lines = s.splitlines()\n",
        "        links = []\n",
        "        nodes = []\n",
        "        label = 0\n",
        "        for l in lines:\n",
        "            if l.strip() == '1.0':\n",
        "                label = 1\n",
        "            if l.strip() == '-1.0':\n",
        "                label = 0\n",
        "            if l.startswith('    '):\n",
        "                feature = l.split()\n",
        "                node = feature[3]\n",
        "                nodes.append(node)\n",
        "            elif l.startswith(' '):\n",
        "                lnk = l.split()\n",
        "                # edge: (from, to,) (1-based index)\n",
        "                if int(lnk[0]) - 1 < len(nodes):\n",
        "                    links.append((\n",
        "                        int(lnk[0])-1, \n",
        "                        int(lnk[1])-1, # zero-based index\n",
        "                        # int(lnk[2]) ignore edge weight\n",
        "                    ))\n",
        "        return nodes, np.array(links), label\n",
        "    \n",
        "    return [parse_sample(s) for s in tqdm(samples) if len(s[0]) > 0]\n",
        "                \n",
        "        \n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Read the train and test set"
      ],
      "metadata": {
        "id": "SUNAKiM4hA3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#read the traing data \n",
        "train = read_sdf('/content/train.sdf')\n",
        "#read the test data \n",
        "test = read_sdf('/content/test_x.sdf')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "ad786a4961b348379333ac9be1b6453e",
            "5685c5357c5d43e38b46d9666527ef46",
            "1ef2440a5fb94ecca679be6011f5c5ef",
            "826607c0b1764e2781d1b2b9d239c1eb",
            "7b36d147e30942c4af5b49a083f6b3f9",
            "578f7757ece7498493896320487382bc",
            "9844385c647e472f880b01b403324f2d",
            "d13d65a4ce5142a4aa83f02ea56690d7",
            "a756c3f635a7446f910772109a7ed90b",
            "bbc87883103e4a828d50aa34db3bafb1",
            "e73cc11cf337404889e22f6b53a463ae",
            "f74466b53e654495801e00571c94761b",
            "5cc662bff3ac492eab197e2b696a9c35",
            "8c035bd0cab84415b4a50d2a8b51a4bc",
            "0ce446bf396344f7be24c2e9b2141c73",
            "983bcafc04fa411f9ca92c7213d9e760",
            "b1042b6361f74b7890392984c4b93cbf",
            "e5f88b4566544a6fa60507411aec4984",
            "3f88ce8c4af541b9bf86a2584c2ae6ba",
            "c908b982b4954208bb5863eae59e31b8",
            "b123ae0d1ee642c0811ec0aa1be9dc71",
            "ed8848a79484485d96c1aa43f37d8e0d"
          ]
        },
        "id": "iQGypQzYUPdu",
        "outputId": "6830c7e6-3dbe-4029-bca6-9b31aa8aedcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/25024 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad786a4961b348379333ac9be1b6453e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/12326 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f74466b53e654495801e00571c94761b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Spilt train set to train validation set"
      ],
      "metadata": {
        "id": "pBUF-9T0V34p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting traing data \n",
        "from sklearn.model_selection import train_test_split\n",
        "X, Y = train_test_split(train, test_size=0.15,)\n",
        "     "
      ],
      "metadata": {
        "id": "LWKW9iomV_3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03S7qeyFWmKL",
        "outputId": "8d13da9b-18d2-4ffb-d1f4-17036a7b3ced"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(['O', 'O', 'O', 'O', 'N', 'N', 'N', 'N', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C'], array([[ 0,  4],\n",
            "       [ 1,  4],\n",
            "       [ 2,  6],\n",
            "       [ 3,  6],\n",
            "       [ 4,  8],\n",
            "       [ 5,  7],\n",
            "       [ 5,  9],\n",
            "       [ 6, 10],\n",
            "       [ 7, 16],\n",
            "       [ 8,  9],\n",
            "       [ 8, 11],\n",
            "       [ 9, 14],\n",
            "       [10, 11],\n",
            "       [10, 15],\n",
            "       [12, 13],\n",
            "       [12, 17],\n",
            "       [12, 19],\n",
            "       [13, 18],\n",
            "       [13, 20],\n",
            "       [14, 15],\n",
            "       [16, 18],\n",
            "       [16, 21],\n",
            "       [17, 22],\n",
            "       [17, 24],\n",
            "       [19, 23],\n",
            "       [20, 23],\n",
            "       [21, 22]]), 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8kRUGDHT0Ra"
      },
      "source": [
        "## Visualizing/Inspecting a Sample üñº"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yk0uh03nT0Ra"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet networkx\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "colors = cm.rainbow(np.linspace(0, 1, 50))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vF7iLI7T0Rb"
      },
      "outputs": [],
      "source": [
        "def visualize(sample):\n",
        "    G=nx.Graph()\n",
        "    nodes = sample[0]\n",
        "    edges = sample[1]\n",
        "    \n",
        "    labeldict={}\n",
        "    node_color=[]\n",
        "    for i,n in enumerate(nodes):\n",
        "        G.add_node(i)\n",
        "        labeldict[i]=n\n",
        "        node_color.append(colors[hash(n)%len(colors)])\n",
        "\n",
        "    # a list of nodes:\n",
        "    for e in edges:\n",
        "        G.add_edge(e[0], e[1])\n",
        "        \n",
        "    nx.draw(G, labels=labeldict, with_labels = True, node_color = node_color)\n",
        "    plt.show()\n",
        "    \n",
        "    return G"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "dbn0H1oyT0Rb",
        "outputId": "40152b73-a9d0-4ed4-8038-9da3851f7ddb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<networkx.classes.graph.Graph at 0x7fc4f83a9f10>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "plt.clf()\n",
        "visualize(X[20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wi2ePmkvT0Rb"
      },
      "source": [
        "#Preprocessing:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Toknization\n",
        "\n",
        "Tokenization is an important step in text preprocessing that can help facilitate downstream NLP tasks."
      ],
      "metadata": {
        "id": "UQyvmZ3XYxKO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoEA4VOkT0Rc"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "max_vocab = 500\n",
        "max_len = 100\n",
        "\n",
        "\n",
        "# build vocabulary from training set\n",
        "all_nodes = [s[0] for s in X]\n",
        "tokenizer = Tokenizer(num_words=max_vocab)\n",
        "tokenizer.fit_on_texts(all_nodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2DYo7j-T0Rc"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import random\n",
        "random.seed(0)\n",
        "\n",
        "def prepare_single_batch(samples):\n",
        "    sample_nodes = [s[0] for s in samples]\n",
        "    sample_nodes = tokenizer.texts_to_sequences(sample_nodes)\n",
        "    sample_nodes = pad_sequences(sample_nodes, padding='post')\n",
        "    max_nodes_len = np.shape(sample_nodes)[1]\n",
        "    edges = [s[1]+i*max_nodes_len for i,s in enumerate(samples)]\n",
        "    edges = [e for e in edges if len(e) > 0]\n",
        "    node_to_graph = [[i]*max_nodes_len for i in range(len(samples))]\n",
        "    \n",
        "    all_nodes = np.reshape(sample_nodes, -1)\n",
        "    all_edges = np.concatenate(edges)\n",
        "\n",
        "    node_to_graph = np.reshape(node_to_graph, -1)\n",
        "    return {\n",
        "        'data': all_nodes,\n",
        "        'edges': all_edges,\n",
        "        'node2grah': node_to_graph,\n",
        "    }, np.array([s[2] for s in samples])\n",
        "\n",
        "\n",
        "\n",
        "def gen_batch(dataset, batch_size=16, repeat=False, shuffle=True):\n",
        "    while True:\n",
        "        dataset = list(dataset)\n",
        "        if shuffle:\n",
        "            random.shuffle(dataset)\n",
        "        l = len(dataset)\n",
        "        for ndx in range(0, l, batch_size):\n",
        "            batch_samples = dataset[ndx:min(ndx + batch_size, l)]\n",
        "            yield prepare_single_batch(batch_samples)\n",
        "        if not repeat:\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSn0_wPoT0Rc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3ac97b8-4978-472a-a534-4d83753616d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data\n",
            "[4 2 2 3 3 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 2 2 2 2 3\n",
            " 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 5 2 2 3 3 3 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 4 3 3 3 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "edges\n",
            "[[  0  23]\n",
            " [  1   9]\n",
            " [  2  13]\n",
            " [  3   4]\n",
            " [  3   7]\n",
            " [  3   9]\n",
            " [  4   8]\n",
            " [  5   7]\n",
            " [  5  10]\n",
            " [  6  12]\n",
            " [  6  13]\n",
            " [  7  14]\n",
            " [  8  11]\n",
            " [  8  13]\n",
            " [  9  10]\n",
            " [ 10  15]\n",
            " [ 11  12]\n",
            " [ 11  16]\n",
            " [ 12  17]\n",
            " [ 14  19]\n",
            " [ 14  20]\n",
            " [ 15  18]\n",
            " [ 16  21]\n",
            " [ 17  22]\n",
            " [ 18  23]\n",
            " [ 18  24]\n",
            " [ 19  25]\n",
            " [ 20  26]\n",
            " [ 21  22]\n",
            " [ 23  28]\n",
            " [ 24  29]\n",
            " [ 25  27]\n",
            " [ 26  27]\n",
            " [ 28  30]\n",
            " [ 29  30]\n",
            " [ 31  34]\n",
            " [ 31  35]\n",
            " [ 31  38]\n",
            " [ 31  53]\n",
            " [ 32  39]\n",
            " [ 32  45]\n",
            " [ 33  44]\n",
            " [ 36  37]\n",
            " [ 36  40]\n",
            " [ 37  52]\n",
            " [ 39  40]\n",
            " [ 39  41]\n",
            " [ 40  42]\n",
            " [ 41  44]\n",
            " [ 41  46]\n",
            " [ 42  43]\n",
            " [ 42  47]\n",
            " [ 43  44]\n",
            " [ 43  49]\n",
            " [ 45  48]\n",
            " [ 45  54]\n",
            " [ 45  55]\n",
            " [ 46  48]\n",
            " [ 47  50]\n",
            " [ 49  51]\n",
            " [ 50  51]\n",
            " [ 52  56]\n",
            " [ 52  57]\n",
            " [ 53  58]\n",
            " [ 53  59]\n",
            " [ 56  58]\n",
            " [ 57  59]\n",
            " [ 62  85]\n",
            " [ 63  69]\n",
            " [ 64  74]\n",
            " [ 65  67]\n",
            " [ 65  68]\n",
            " [ 65  69]\n",
            " [ 66  68]\n",
            " [ 66  71]\n",
            " [ 67  74]\n",
            " [ 68  72]\n",
            " [ 69  70]\n",
            " [ 70  71]\n",
            " [ 70  73]\n",
            " [ 71  75]\n",
            " [ 72  77]\n",
            " [ 72  78]\n",
            " [ 73  79]\n",
            " [ 74  76]\n",
            " [ 75  80]\n",
            " [ 76  81]\n",
            " [ 76  82]\n",
            " [ 77  83]\n",
            " [ 78  84]\n",
            " [ 79  80]\n",
            " [ 81  87]\n",
            " [ 82  88]\n",
            " [ 83  86]\n",
            " [ 84  86]\n",
            " [ 85  87]\n",
            " [ 85  88]\n",
            " [ 93 103]\n",
            " [ 93 106]\n",
            " [ 94  97]\n",
            " [ 94  98]\n",
            " [ 95  97]\n",
            " [ 95  99]\n",
            " [ 96 100]\n",
            " [ 96 106]\n",
            " [ 97 100]\n",
            " [ 98  99]\n",
            " [ 98 101]\n",
            " [ 99 102]\n",
            " [100 103]\n",
            " [101 104]\n",
            " [102 105]\n",
            " [104 105]]\n",
            "node2grah\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
            "label [0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "# showing one batch:\n",
        "for train_batch in gen_batch(X, batch_size=4):\n",
        "    for k,v in train_batch[0].items():\n",
        "        print(k)\n",
        "        print(v)\n",
        "        pass\n",
        "    print('label', train_batch[1])\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The First Trail\n",
        "#GNN\n",
        "GNNs are particularly useful in scenarios where the data is structured as a graph, which consists of nodes and edges that connect them. GNNs can learn to effectively capture information from the graph structure, such as local and global relationships between nodes, and use this information to make predictions or perform other tasks.\n",
        "\n"
      ],
      "metadata": {
        "id": "0xRbG0ZQZT0J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GNNs can be a powerful tool for anti-cancer activity prediction, leveraging the structure of molecular and drug interaction networks to identify potential therapeutics.\n",
        "we will check that:\n",
        "\n"
      ],
      "metadata": {
        "id": "2RVgwobtZ5gp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`I have no expectation how it will perform`\n"
      ],
      "metadata": {
        "id": "cvt-k7xVYI2q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_DXT5IAT0Rd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8e100b6-105c-49fd-bf50-17f11a4245a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/54.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m135.5/135.5 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m388.0/388.0 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m173.9/173.9 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for tf2_gnn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install --quiet tf2_gnn\n",
        "\n",
        "# https://github.com/microsoft/tf2-gnn\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "\n",
        "from tf2_gnn.layers.gnn import GNN, GNNInput"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OfkRc9dT0Rd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f491873-4949-474a-c869-1032761539f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='gnn/StatefulPartitionedCall:0', description=\"created by layer 'gnn'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='tf.math.segment_mean/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense/Sigmoid:0', description=\"created by layer 'dense'\")\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max (TFOpLambda  ()                  0           ['input_3[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 20)           10000       ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOpLamb  ()                  0           ['tf.math.reduce_max[0][0]']     \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " gnn (GNN)                      (None, 32)           22464       ['embedding[0][0]',              \n",
            "                                                                  'input_2[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'tf.__operators__.add[0][0]']   \n",
            "                                                                                                  \n",
            " tf.math.segment_mean (TFOpLamb  (None, 32)          0           ['gnn[0][0]',                    \n",
            " da)                                                              'input_3[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1)            33          ['tf.math.segment_mean[0][0]']   \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 32,497\n",
            "Trainable params: 32,497\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Import the necessary modules\n",
        "import tensorflow as tf\n",
        "from tensorflow.math import segment_mean\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import Embedding, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "#Define the input for the node features (a batch of sequences of tokens)\n",
        "data = keras.Input(batch_shape=(None,))\n",
        "\n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
        "\n",
        "# number of graphs (number of samples)\n",
        "# Compute the maximum graph index in the node2graph array\n",
        "num_graph = tf.reduce_max(node2graph)+1\n",
        "\n",
        "# Create a GNNInput object that contains the node features, adjacency lists,\n",
        "# node to graph map, and number of graphs\n",
        "gnn_input = GNNInput(\n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge,),\n",
        "    node_to_graph_map=node2graph, \n",
        "    num_graphs=num_graph,\n",
        ")\n",
        "\n",
        "\n",
        "# Get the default hyperparameters for the GNN model and set the hidden dimension to 32\n",
        "params = GNN.get_default_hyperparameters()\n",
        "params[\"hidden_dim\"] = 32\n",
        "\n",
        "# Create a GNN layer with the given parameters\n",
        "gnn_layer = GNN(params)\n",
        "# Apply the GNN layer to the input and get the output node representations\n",
        "gnn_out = gnn_layer(gnn_input)\n",
        "\n",
        "# Print the shape and values of gnn_out\n",
        "print('gnn_out', gnn_out)\n",
        "\n",
        "# Compute the mean of the node representations for each graph using segment_mean\n",
        "avg = segment_mean(\n",
        "    data=gnn_out,\n",
        "    segment_ids=node2graph\n",
        ")\n",
        "\n",
        "# Print the shape and values of avg\n",
        "print('mean:', avg)\n",
        "\n",
        "pred = Dense(1, activation='sigmoid')(avg)\n",
        "print('pred:', pred)\n",
        "\n",
        "model = Model(\n",
        "    inputs={\n",
        "        'data': data,\n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs=pred\n",
        ")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rx7Q0AQ6T0Rd"
      },
      "outputs": [],
      "source": [
        "#Set up the model for binary classification with BinaryCrossentropy loss and AUC metric\n",
        "model.compile(\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7Nn3DpJT0Rd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d23f4682-95da-4db6-ab49-45861dfdbfb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1330/1330 [==============================] - 48s 32ms/step - loss: 0.2286 - auc: 0.5057 - val_loss: 0.2021 - val_auc: 0.6234\n",
            "Epoch 2/5\n",
            "1330/1330 [==============================] - 24s 18ms/step - loss: 0.1931 - auc: 0.6186 - val_loss: 0.1923 - val_auc: 0.6978\n",
            "Epoch 3/5\n",
            "1330/1330 [==============================] - 25s 19ms/step - loss: 0.1895 - auc: 0.6439 - val_loss: 0.1912 - val_auc: 0.7121\n",
            "Epoch 4/5\n",
            "1330/1330 [==============================] - 28s 21ms/step - loss: 0.1878 - auc: 0.6519 - val_loss: 0.1872 - val_auc: 0.7148\n",
            "Epoch 5/5\n",
            "1330/1330 [==============================] - 41s 31ms/step - loss: 0.1867 - auc: 0.6603 - val_loss: 0.1903 - val_auc: 0.7261\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6672319f10>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "#Train the model for 5 epochs using a custom data generator and batch size of 16\n",
        "import math\n",
        "\n",
        "batch_size = 16\n",
        "num_batchs = math.ceil(len(X) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(Y) / batch_size)\n",
        "\n",
        "model.fit(\n",
        "    gen_batch(\n",
        "        X, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=5,\n",
        "    validation_data=gen_batch(\n",
        "        Y, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predition\n",
        "\n",
        "We can use the model to predict the testing samples."
      ],
      "metadata": {
        "id": "FdVbNitNBynm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4q580E1JT0Re",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b9fbd89-0796-44b7-fb9e-8051315ac15d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "771/771 [==============================] - 6s 7ms/step\n"
          ]
        }
      ],
      "source": [
        "# Use the model to make predictions on the test data\n",
        "# The test data is generated in batches of 16 and not shuffled\n",
        "y_pred = model.predict(\n",
        "    gen_batch(test, batch_size=16, shuffle=False)\n",
        ")\n",
        "# Reshape the predictions to a one-dimensional array\n",
        "y_pred = np.reshape(y_pred, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WnIKNqaaT0Re",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b653813-2529-4a6d-fee6-b8b2b78200f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12326"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "len(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPfRybLoT0Re"
      },
      "outputs": [],
      "source": [
        "#  (if for kaggle competition and it is about genre prediction)\n",
        "import pandas as pd \n",
        "submission = pd.DataFrame({'label':y_pred})\n",
        "submission.index.name = 'id'\n",
        "submission.to_csv('sample_submission.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This trail get score 0.71461 on Kaggle.\n",
        "`it's not bad there is no overfitting or underfitting.`"
      ],
      "metadata": {
        "id": "inoLVU8xaet9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The Secound Trail\n",
        "#RGCN\n",
        "\n",
        "RGCN, or Relational Graph Convolution Network , is a type of Graph Neural Network (GNN) that can be used for modeling relational data. Specifically, RGCNs can be used for link prediction and recommendation systems, where the goal is to predict the presence or absence of a connection between two entities in a graph.\n",
        "\n",
        "may require experimentation and testing to determine the most effective approach. \n",
        "\n",
        "RGCNs can be used to predict the efficacy of potential drugs based on their molecular structures and relationships with biological targets. By analyzing the graph structure of the relationship network between drugs, molecular structures, and biological targets, RGCNs can learn to extract features that are important in predicting the anti-cancer activity of compounds.\n",
        "\n",
        "RGCNs can provide a powerful tool for anti-cancer activity prediction by leveraging the structure of relational data and identifying key features and relationships that are important in predicting cancer outcomes, an RGCN model could be a suitable choice\n"
      ],
      "metadata": {
        "id": "RWqhyBRPawVY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`I expect the performance will be better than the previous trail.`\n"
      ],
      "metadata": {
        "id": "bQLVypyzY21k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FR0m_1sAcVOr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "439b820f-cad7-4a43-aced-a3391109c8e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rgcn_out KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='gnn_2/StatefulPartitionedCall:0', description=\"created by layer 'gnn_2'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='tf.math.segment_mean_2/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_2'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_2/Sigmoid:0', description=\"created by layer 'dense_2'\")\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_15 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_13 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_3 (TFOpLamb  ()                  0           ['input_15[0][0]']               \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_4 (Embedding)        (None, 20)           10000       ['input_13[0][0]']               \n",
            "                                                                                                  \n",
            " input_14 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_3 (TFOpLa  ()                  0           ['tf.math.reduce_max_3[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_2 (GNN)                    (None, 64)           71552       ['embedding_4[0][0]',            \n",
            "                                                                  'input_14[0][0]',               \n",
            "                                                                  'input_15[0][0]',               \n",
            "                                                                  'tf.__operators__.add_3[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_2 (TFOpLa  (None, 64)          0           ['gnn_2[0][0]',                  \n",
            " mbda)                                                            'input_15[0][0]']               \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 1)            65          ['tf.math.segment_mean_2[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 81,617\n",
            "Trainable params: 81,617\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Import the necessary modules\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, Lambda\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "#Define the input for the node features (a batch of sequences of tokens)\n",
        "data = Input(batch_shape=(None,))\n",
        "\n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "edge_index = Input(batch_shape=(None, 2),  dtype=tf.int32)\n",
        "node2graph = Input(batch_shape=(None,), dtype=tf.int32)\n",
        "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
        "\n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1\n",
        "\n",
        "# Define the RGCN layer\n",
        "rgcn_input = GNNInput( \n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge_index,),\n",
        "    node_to_graph_map=node2graph,\n",
        "    num_graphs=num_graph, \n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "#Get the default hyperparameters for the GNN model and set the hidden dimension to 64\n",
        "\n",
        "params1 = GNN.get_default_hyperparameters()\n",
        "params1[\"hidden_dim\"] = 64\n",
        "params1[\"num_aggr_MLP_HIDDEN_LAYERS\"] = 32\n",
        "params1['message_calculation_class']= 'RGCN'\n",
        "\n",
        "#Create a RGCN layer with the given parameters\n",
        "\n",
        "rgcn_layer = GNN(params1)\n",
        "\n",
        "#Apply the RGCN layer to the input and get the output node representations\n",
        "rgcn_out = rgcn_layer(rgcn_input)\n",
        "\n",
        "#Print the shape and values of rgcn_out\n",
        "print('rgcn_out', rgcn_out)\n",
        "\n",
        "#Compute the mean of the node representations for each graph using segment_mean\n",
        "avg = segment_mean(\n",
        "    data=rgcn_out,\n",
        "    segment_ids=node2graph\n",
        ")\n",
        "\n",
        "#Print the shape and values of avg\n",
        "print('mean:', avg)\n",
        "\n",
        "\n",
        "#Apply a dense layer with sigmoid activation to get the prediction for each graph\n",
        "pred1 = Dense(1, activation='sigmoid')(avg)\n",
        "print('pred:', pred1)\n",
        "\n",
        "#Define the model with inputs and outputs\n",
        "model1 = Model(\n",
        "    inputs={\n",
        "        'data': data,\n",
        "        'edges': edge_index,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs=pred1\n",
        ")\n",
        "model1.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSKrA67IcVOy"
      },
      "outputs": [],
      "source": [
        "#Set up the model for binary classification with BinaryCrossentropy loss and AUC metric\n",
        "model1.compile(\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdECYIaHcVOy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0b2ba16-876e-4b21-d859-a6358f4f5189"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "665/665 [==============================] - 37s 56ms/step - loss: 0.1956 - auc: 0.6096 - val_loss: 0.2016 - val_auc: 0.6532\n",
            "Epoch 2/15\n",
            "665/665 [==============================] - 38s 57ms/step - loss: 0.1893 - auc: 0.6500 - val_loss: 0.1922 - val_auc: 0.6962\n",
            "Epoch 3/15\n",
            "665/665 [==============================] - 37s 55ms/step - loss: 0.1856 - auc: 0.6704 - val_loss: 0.1871 - val_auc: 0.7154\n",
            "Epoch 4/15\n",
            "665/665 [==============================] - 36s 54ms/step - loss: 0.1846 - auc: 0.6773 - val_loss: 0.1827 - val_auc: 0.7275\n",
            "Epoch 5/15\n",
            "665/665 [==============================] - 37s 55ms/step - loss: 0.1818 - auc: 0.6916 - val_loss: 0.2109 - val_auc: 0.7065\n",
            "Epoch 6/15\n",
            "665/665 [==============================] - 37s 55ms/step - loss: 0.1796 - auc: 0.7016 - val_loss: 0.1780 - val_auc: 0.7355\n",
            "Epoch 7/15\n",
            "665/665 [==============================] - 36s 54ms/step - loss: 0.1780 - auc: 0.7147 - val_loss: 0.1807 - val_auc: 0.7383\n",
            "Epoch 8/15\n",
            "665/665 [==============================] - 36s 55ms/step - loss: 0.1769 - auc: 0.7183 - val_loss: 0.1767 - val_auc: 0.7509\n",
            "Epoch 9/15\n",
            "665/665 [==============================] - 37s 55ms/step - loss: 0.1761 - auc: 0.7198 - val_loss: 0.1846 - val_auc: 0.7491\n",
            "Epoch 10/15\n",
            "665/665 [==============================] - 36s 53ms/step - loss: 0.1774 - auc: 0.7153 - val_loss: 0.1914 - val_auc: 0.7549\n",
            "Epoch 11/15\n",
            "665/665 [==============================] - 37s 56ms/step - loss: 0.1769 - auc: 0.7191 - val_loss: 0.1844 - val_auc: 0.7374\n",
            "Epoch 12/15\n",
            "665/665 [==============================] - 37s 55ms/step - loss: 0.1753 - auc: 0.7290 - val_loss: 0.1796 - val_auc: 0.7594\n",
            "Epoch 13/15\n",
            "665/665 [==============================] - 35s 53ms/step - loss: 0.1728 - auc: 0.7368 - val_loss: 0.1823 - val_auc: 0.7479\n",
            "Epoch 14/15\n",
            "665/665 [==============================] - 35s 53ms/step - loss: 0.1734 - auc: 0.7325 - val_loss: 0.1741 - val_auc: 0.7694\n",
            "Epoch 15/15\n",
            "665/665 [==============================] - 36s 54ms/step - loss: 0.1721 - auc: 0.7399 - val_loss: 0.1748 - val_auc: 0.7664\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f66703970a0>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "#Train the model for 15 epochs using a custom data generator and batch size of 32\n",
        "\n",
        "import math\n",
        "\n",
        "batch_size = 32\n",
        "num_batchs = math.ceil(len(X) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(Y) / batch_size)\n",
        "\n",
        "model1.fit(\n",
        "    gen_batch(\n",
        "        X, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=15,\n",
        "    validation_data=gen_batch(\n",
        "        Y, batch_size=32, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I--7SbwCcVOz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f365c87-c51c-4639-98f6-ab3645d55340"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "771/771 [==============================] - 9s 11ms/step\n"
          ]
        }
      ],
      "source": [
        "# Use the model to make predictions on the test data\n",
        "# The test data is generated in batches of 16 and not shuffled\n",
        "y_pred1 = model1.predict(\n",
        "    gen_batch(test, batch_size=16, shuffle=False)\n",
        ")\n",
        "# Reshape the predictions to a one-dimensional array\n",
        "y_pred1 = np.reshape(y_pred1, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDa8atPvcVOz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a8079d2-c7da-443b-eca6-58dd99ea4fcb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12326"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "len(y_pred1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leuDVuoOcVOz"
      },
      "outputs": [],
      "source": [
        "#  (if for kaggle competition and it is about genre prediction)\n",
        "import pandas as pd \n",
        "submission = pd.DataFrame({'label':y_pred1})\n",
        "submission.index.name = 'id'\n",
        "submission.to_csv('sample_submission1.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This trail get score 0.76522 on Kaggle "
      ],
      "metadata": {
        "id": "PfRp6xDz2Ano"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`it's better than the previous trail and there is no overfitting or underfitting.`"
      ],
      "metadata": {
        "id": "SVEITrZVZKqp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Third trail\n",
        "# RGAT\n",
        "\n",
        "\n",
        "*   The Relational Graph Attention Network (RGAT) is a type of graph neural network (GNN) that is used for processing relationships between entities in a graph. \n",
        "\n",
        "*   RGATs are specifically designed to address the limitations of previous GNNs, such as the Graph Convolutional Network (GCN), which only consider a fixed edge weight for all nodes. RGATs model the relationships between pairs of nodes as edge weights and then use attention mechanisms to weigh these relationships, allowing the network to learn which relationships are most important for a given task.\n",
        "\n",
        "*   The main advantages of using RGAT over other GNNs include:\n",
        "\n",
        "      * Improved ability to capture complex dependencies in the graph\n",
        "\n",
        "      * Improved interpretability of the learned representation\n",
        "\n",
        "      * Improved performance on tasks that require reasoning about relationships between nodes\n",
        "*   Relational Graph Attention Network (RGAT) can be used for anti-cancer activity prediction by modeling relationships between entities such as molecular structures and biological activity using a graph. The RGAT architecture can learn to weigh relationships between entities, allowing it to capture complex dependencies in the graph and identify the most important relationships for predicting anti-cancer activity.\n",
        "*   RGAT could be a powerful tool for anti-cancer activity prediction, especially when the dependencies between molecular structures are complex and difficult to capture with traditional machine learning techniques.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kY_eOAzk2Ng2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`I expect the performance will be better than the previous trails.`\n"
      ],
      "metadata": {
        "id": "XIWmUoqKZslT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a114acdf-d21b-43aa-db4a-fa158da40804",
        "id": "DQ2IvtMZ4NA6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rgan_out KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='gnn_4/StatefulPartitionedCall:0', description=\"created by layer 'gnn_4'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='tf.math.segment_mean_3/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_3'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_3/Sigmoid:0', description=\"created by layer 'dense_3'\")\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_21 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_19 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_5 (TFOpLamb  ()                  0           ['input_21[0][0]']               \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_6 (Embedding)        (None, 20)           10000       ['input_19[0][0]']               \n",
            "                                                                                                  \n",
            " input_20 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_5 (TFOpLa  ()                  0           ['tf.math.reduce_max_5[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_4 (GNN)                    (None, 64)           72064       ['embedding_6[0][0]',            \n",
            "                                                                  'input_20[0][0]',               \n",
            "                                                                  'input_21[0][0]',               \n",
            "                                                                  'tf.__operators__.add_5[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_3 (TFOpLa  (None, 64)          0           ['gnn_4[0][0]',                  \n",
            " mbda)                                                            'input_21[0][0]']               \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 1)            65          ['tf.math.segment_mean_3[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 82,129\n",
            "Trainable params: 82,129\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Define the input for the node features (a batch of sequences of tokens)\n",
        "data = Input(batch_shape=(None,))\n",
        "\n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "edge_index = Input(batch_shape=(None, 2),  dtype=tf.int32)\n",
        "node2graph = Input(batch_shape=(None,), dtype=tf.int32)\n",
        "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
        "\n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1\n",
        "\n",
        "# Define the RGAT layer\n",
        "rgat_input = GNNInput( \n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge_index,),\n",
        "    node_to_graph_map=node2graph,\n",
        "    num_graphs=num_graph, \n",
        ")\n",
        "\n",
        "\n",
        "#Get the default hyperparameters for the GNN model and set the hidden dimension to 64\n",
        "\n",
        "params2 = GNN.get_default_hyperparameters()\n",
        "params2[\"hidden_dim\"] = 64\n",
        "#Set the number of hidden layers for the aggregation MLP to 32\n",
        "params2[\"num_aggr_MLP_HIDDEN_LAYERS\"] = 32\n",
        "#Set the message calculation class to RGAT (Relational Graph Attention Network)\n",
        "params2['message_calculation_class']= 'RGAT'\n",
        "#Set the number of attention heads to 4\n",
        "params2['num_heads']= 4\n",
        "#Create a GNN layer with the given parameters\n",
        "rgat_layer = GNN(params2)\n",
        "#Apply the GNN layer to the input and get the output node representations\n",
        "rgat_out = rgat_layer(rgat_input)\n",
        "#Print the shape and values of rgat_out\n",
        "print('rgat_out', rgat_out)\n",
        "\n",
        "#Compute the mean of the node representations for each graph using segment_mean\n",
        "avg = segment_mean(\n",
        "    data=rgat_out,\n",
        "    segment_ids=node2graph\n",
        ")\n",
        "\n",
        "#Print the shape and values of avg\n",
        "print('mean:', avg)\n",
        "\n",
        "#Apply a dense layer with sigmoid activation to get the prediction for each graph\n",
        "pred2 = Dense(1, activation='sigmoid')(avg)\n",
        "print('pred:', pred2)\n",
        "\n",
        "#Define the model with inputs and outputs\n",
        "model2 = Model(\n",
        "    inputs={\n",
        "        'data': data,\n",
        "        'edges': edge_index,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs=pred2\n",
        ")\n",
        "model2.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Afer8mDh4NA7"
      },
      "outputs": [],
      "source": [
        "#Set up the model for binary classification with BinaryCrossentropy loss and AUC metric\n",
        "model2.compile(\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e092b0d-51a3-4f78-d0eb-313b8dcd9321",
        "id": "0bcjSzUo4NA7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "665/665 [==============================] - 53s 80ms/step - loss: 0.1692 - auc: 0.7557 - val_loss: 0.1782 - val_auc: 0.7706\n",
            "Epoch 2/30\n",
            "665/665 [==============================] - 53s 80ms/step - loss: 0.1706 - auc: 0.7538 - val_loss: 0.1778 - val_auc: 0.7624\n",
            "Epoch 3/30\n",
            "665/665 [==============================] - 53s 80ms/step - loss: 0.1688 - auc: 0.7656 - val_loss: 0.1654 - val_auc: 0.7716\n",
            "Epoch 4/30\n",
            "665/665 [==============================] - 52s 79ms/step - loss: 0.1707 - auc: 0.7505 - val_loss: 0.1806 - val_auc: 0.7411\n",
            "Epoch 5/30\n",
            "665/665 [==============================] - 53s 80ms/step - loss: 0.1693 - auc: 0.7539 - val_loss: 0.1749 - val_auc: 0.7639\n",
            "Epoch 6/30\n",
            "665/665 [==============================] - 53s 80ms/step - loss: 0.1702 - auc: 0.7476 - val_loss: 0.2016 - val_auc: 0.7356\n",
            "Epoch 7/30\n",
            "665/665 [==============================] - 53s 80ms/step - loss: 0.1700 - auc: 0.7509 - val_loss: 0.1689 - val_auc: 0.7510\n",
            "Epoch 8/30\n",
            "665/665 [==============================] - 53s 79ms/step - loss: 0.1675 - auc: 0.7629 - val_loss: 0.1784 - val_auc: 0.7673\n",
            "Epoch 9/30\n",
            "665/665 [==============================] - 52s 79ms/step - loss: 0.1678 - auc: 0.7618 - val_loss: 0.1647 - val_auc: 0.7630\n",
            "Epoch 10/30\n",
            "665/665 [==============================] - 54s 81ms/step - loss: 0.1668 - auc: 0.7623 - val_loss: 0.1960 - val_auc: 0.7483\n",
            "Epoch 11/30\n",
            "665/665 [==============================] - 55s 82ms/step - loss: 0.1664 - auc: 0.7665 - val_loss: 0.1988 - val_auc: 0.7382\n",
            "Epoch 12/30\n",
            "665/665 [==============================] - 53s 80ms/step - loss: 0.1667 - auc: 0.7644 - val_loss: 0.1632 - val_auc: 0.7772\n",
            "Epoch 13/30\n",
            "665/665 [==============================] - 54s 82ms/step - loss: 0.1667 - auc: 0.7660 - val_loss: 0.1701 - val_auc: 0.7745\n",
            "Epoch 14/30\n",
            "665/665 [==============================] - 53s 80ms/step - loss: 0.1647 - auc: 0.7749 - val_loss: 0.1845 - val_auc: 0.7587\n",
            "Epoch 15/30\n",
            "665/665 [==============================] - 54s 82ms/step - loss: 0.1667 - auc: 0.7645 - val_loss: 0.1663 - val_auc: 0.7890\n",
            "Epoch 16/30\n",
            "665/665 [==============================] - 54s 82ms/step - loss: 0.1663 - auc: 0.7674 - val_loss: 0.1772 - val_auc: 0.7474\n",
            "Epoch 17/30\n",
            "665/665 [==============================] - 54s 81ms/step - loss: 0.1646 - auc: 0.7769 - val_loss: 0.1745 - val_auc: 0.7720\n",
            "Epoch 18/30\n",
            "665/665 [==============================] - 52s 78ms/step - loss: 0.1646 - auc: 0.7719 - val_loss: 0.2127 - val_auc: 0.7182\n",
            "Epoch 19/30\n",
            "665/665 [==============================] - 55s 82ms/step - loss: 0.1642 - auc: 0.7755 - val_loss: 0.1816 - val_auc: 0.7354\n",
            "Epoch 20/30\n",
            "665/665 [==============================] - 54s 82ms/step - loss: 0.1648 - auc: 0.7721 - val_loss: 0.1796 - val_auc: 0.7699\n",
            "Epoch 21/30\n",
            "665/665 [==============================] - 55s 83ms/step - loss: 0.1648 - auc: 0.7746 - val_loss: 0.1836 - val_auc: 0.7609\n",
            "Epoch 22/30\n",
            "665/665 [==============================] - 52s 79ms/step - loss: 0.1641 - auc: 0.7763 - val_loss: 0.1770 - val_auc: 0.7676\n",
            "Epoch 23/30\n",
            "665/665 [==============================] - 53s 79ms/step - loss: 0.1645 - auc: 0.7752 - val_loss: 0.1726 - val_auc: 0.7688\n",
            "Epoch 24/30\n",
            "665/665 [==============================] - 54s 81ms/step - loss: 0.1656 - auc: 0.7693 - val_loss: 0.1664 - val_auc: 0.7795\n",
            "Epoch 25/30\n",
            "665/665 [==============================] - 52s 79ms/step - loss: 0.1619 - auc: 0.7854 - val_loss: 0.1835 - val_auc: 0.7722\n",
            "Epoch 26/30\n",
            "665/665 [==============================] - 54s 82ms/step - loss: 0.1629 - auc: 0.7783 - val_loss: 0.1888 - val_auc: 0.7552\n",
            "Epoch 27/30\n",
            "665/665 [==============================] - 54s 81ms/step - loss: 0.1609 - auc: 0.7864 - val_loss: 0.1754 - val_auc: 0.7443\n",
            "Epoch 28/30\n",
            "665/665 [==============================] - 54s 82ms/step - loss: 0.1629 - auc: 0.7762 - val_loss: 0.1757 - val_auc: 0.7726\n",
            "Epoch 29/30\n",
            "665/665 [==============================] - 55s 82ms/step - loss: 0.1623 - auc: 0.7799 - val_loss: 0.1674 - val_auc: 0.7858\n",
            "Epoch 30/30\n",
            "665/665 [==============================] - 53s 80ms/step - loss: 0.1615 - auc: 0.7823 - val_loss: 0.1771 - val_auc: 0.7634\n"
          ]
        }
      ],
      "source": [
        "#Train the model for 30 epochs using a custom data generator and batch size of 32\n",
        "\n",
        "import math\n",
        "\n",
        "batch_size = 32\n",
        "num_batchs = math.ceil(len(X) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(Y) / batch_size)\n",
        "\n",
        "history = model2.fit(\n",
        "    gen_batch(\n",
        "        X, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=30,\n",
        "    validation_data=gen_batch(\n",
        "        Y, batch_size=50, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a5d98fc-6510-4c5c-8206-efd13c13d851",
        "id": "9NBi1uY74NA7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "386/386 [==============================] - 9s 21ms/step\n"
          ]
        }
      ],
      "source": [
        "# Use the model to make predictions on the test data\n",
        "# The test data is generated in batches of 32 and not shuffled\n",
        "y_pred2 = model2.predict(\n",
        "    gen_batch(test, batch_size=32, shuffle=False)\n",
        ")\n",
        "# Reshape the predictions to a one-dimensional array\n",
        "y_pred2 = np.reshape(y_pred2, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dd0f97a-a0a7-47ce-c495-698d1d14ecb0",
        "id": "VXy6ydP64NA7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12326"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "len(y_pred2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfeyzTwk4NA8"
      },
      "outputs": [],
      "source": [
        "#  (if for kaggle competition and it is about genre prediction)\n",
        "import pandas as pd \n",
        "submission = pd.DataFrame({'label':y_pred2})\n",
        "submission.index.name = 'id'\n",
        "submission.to_csv('sample_submission2.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This trail get score 0.77885 on Kaggle "
      ],
      "metadata": {
        "id": "DaOU8k7v4NA8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`it's better than the previous trail and there is no overfitting or underfitting.`"
      ],
      "metadata": {
        "id": "VqHbh5_mZ1BZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The Fourth trail\n",
        "#RGIN\n",
        "\n",
        "* a Relational Graph Isomorphism Network (RGIN) is a type of Graph Neural Network (GNN) that has a high discriminative power and can capture complex structural patterns in graphs. It is based on the idea of the Weisfeiler-Lehman test, which is a method to check if two graphs are isomorphic, i.e., have the same structure. A RGIN uses a simple aggregator function that updates the node features by adding the sum of the neighbor features and applying a nonlinear transformation. This way, it can preserve the node identity and distinguish between different graph structures. This way, it can preserve the node identity and distinguish between different graph structures.\n",
        "* We set the message calculation class to RGIN when we want to use this powerful GNN architecture for graph representation learning tasks, such as node classification, graph classification, or link prediction. RGIN can learn more expressive and informative node embeddings than other GNN models, such as GCN or GraphSAGE, which use more complex aggregators that may lose some structural information. RGIN can also handle graphs with different types of edges or relations, by using different weight matrices for each edge type.\n",
        "* RGIN can learn the structural and relational features of ACPs and their interactions with cancer cell membranes, and predict their anti-cancer activity based on their node embeddings. RGIN can also provide interpretable explanations for the predictions by highlighting the important nodes and edges that contribute to the anti-cancer activity of ACPs. \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MTjr2GixEx8k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`I have no expectations let's see what happens`"
      ],
      "metadata": {
        "id": "XGg_qZsTZ2hC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d22d8fbe-cf72-4fb1-b4ee-ff575b939b23",
        "id": "Ib5Tad7yMroC"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rgin_out KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='gnn_2/StatefulPartitionedCall:0', description=\"created by layer 'gnn_2'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='tf.math.segment_mean_2/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_2'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_2/Sigmoid:0', description=\"created by layer 'dense_2'\")\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_9 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_7 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_2 (TFOpLamb  ()                  0           ['input_9[0][0]']                \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)        (None, 20)           10000       ['input_7[0][0]']                \n",
            "                                                                                                  \n",
            " input_8 (InputLayer)           [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_2 (TFOpLa  ()                  0           ['tf.math.reduce_max_2[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_2 (GNN)                    (None, 64)           1136512     ['embedding_2[0][0]',            \n",
            "                                                                  'input_8[0][0]',                \n",
            "                                                                  'input_9[0][0]',                \n",
            "                                                                  'tf.__operators__.add_2[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_2 (TFOpLa  (None, 64)          0           ['gnn_2[0][0]',                  \n",
            " mbda)                                                            'input_9[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 1)            65          ['tf.math.segment_mean_2[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,146,577\n",
            "Trainable params: 1,146,577\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Define the input for the node features (a batch of sequences of tokens)\n",
        "data = Input(batch_shape=(None,))\n",
        "\n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "edge_index = Input(batch_shape=(None, 2),  dtype=tf.int32)\n",
        "node2graph = Input(batch_shape=(None,), dtype=tf.int32)\n",
        "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
        "\n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1\n",
        "\n",
        "# Define the RGIN layer\n",
        "rgin_input = GNNInput( \n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge_index,),\n",
        "    node_to_graph_map=node2graph,\n",
        "    num_graphs=num_graph, \n",
        ")\n",
        "\n",
        "#Get the default hyperparameters for the GNN model and set the hidden dimension to 64\n",
        "params3 = GNN.get_default_hyperparameters()\n",
        "params3[\"hidden_dim\"] = 64\n",
        "#Set the number of hidden layers for the aggregation MLP to 64\n",
        "params3[\"num_aggr_MLP_hidden_layers\"] = 64\n",
        "#Set the message calculation class to RGIN (Relational Graph Isomorphism Network)\n",
        "params3['message_calculation_class']= 'RGIN'\n",
        "\n",
        "#Create a GNN layer with the given parameters\n",
        "rgin_layer = GNN(params3)\n",
        "\n",
        "#Apply the GNN layer to the input and get the output node representations\n",
        "rgin_out = rgin_layer(rgin_input)\n",
        "\n",
        "#Print the shape and values of rgin_out\n",
        "print('rgin_out', rgin_out)\n",
        "\n",
        "#Compute the mean of the node representations for each graph using segment_mean\n",
        "avg = segment_mean(\n",
        "    data=rgin_out,\n",
        "    segment_ids=node2graph\n",
        ")\n",
        "\n",
        "#Print the shape and values of avg\n",
        "print('mean:', avg)\n",
        "\n",
        "\n",
        "#Apply a dense layer with sigmoid activation to get the prediction for each graph\n",
        "pred3 = Dense(1, activation='sigmoid')(avg)\n",
        "print('pred:', pred3)\n",
        "\n",
        "#Define the model with inputs and outputs\n",
        "model3 = Model(\n",
        "    inputs={\n",
        "        'data': data,\n",
        "        'edges': edge_index,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs=pred3\n",
        ")\n",
        "model3.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNYiEXEmMroD"
      },
      "outputs": [],
      "source": [
        "#Set up the model for binary classification with BinaryCrossentropy loss and AUC metric\n",
        "model3.compile(\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a7a479c-b8e8-4cca-a9bd-f9bfb92efaa5",
        "id": "YvQ0tFUDMroE"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "665/665 [==============================] - 39s 59ms/step - loss: 0.5582 - auc: 0.5033 - val_loss: 0.4519 - val_auc: 0.5000\n",
            "Epoch 2/30\n",
            "665/665 [==============================] - 34s 51ms/step - loss: 0.3652 - auc: 0.5060 - val_loss: 0.3123 - val_auc: 0.5000\n",
            "Epoch 3/30\n",
            "665/665 [==============================] - 31s 47ms/step - loss: 0.2576 - auc: 0.5027 - val_loss: 0.2443 - val_auc: 0.5000\n",
            "Epoch 4/30\n",
            "665/665 [==============================] - 32s 49ms/step - loss: 0.2090 - auc: 0.5109 - val_loss: 0.2228 - val_auc: 0.5000\n",
            "Epoch 5/30\n",
            "665/665 [==============================] - 32s 47ms/step - loss: 0.1941 - auc: 0.4825 - val_loss: 0.2158 - val_auc: 0.5000\n",
            "Epoch 6/30\n",
            "665/665 [==============================] - 32s 49ms/step - loss: 0.1909 - auc: 0.4992 - val_loss: 0.2205 - val_auc: 0.5000\n",
            "Epoch 7/30\n",
            "665/665 [==============================] - 31s 47ms/step - loss: 0.1903 - auc: 0.4928 - val_loss: 0.2233 - val_auc: 0.5000\n",
            "Epoch 8/30\n",
            "665/665 [==============================] - 33s 50ms/step - loss: 0.1902 - auc: 0.5000 - val_loss: 0.2132 - val_auc: 0.5000\n",
            "Epoch 9/30\n",
            "665/665 [==============================] - 33s 50ms/step - loss: 0.1902 - auc: 0.5000 - val_loss: 0.2255 - val_auc: 0.5000\n",
            "Epoch 10/30\n",
            "665/665 [==============================] - 32s 48ms/step - loss: 0.1902 - auc: 0.5000 - val_loss: 0.2166 - val_auc: 0.5000\n",
            "Epoch 11/30\n",
            "665/665 [==============================] - 33s 49ms/step - loss: 0.1902 - auc: 0.5000 - val_loss: 0.2230 - val_auc: 0.5000\n",
            "Epoch 12/30\n",
            "665/665 [==============================] - 33s 50ms/step - loss: 0.1902 - auc: 0.4996 - val_loss: 0.2166 - val_auc: 0.5000\n",
            "Epoch 13/30\n",
            "665/665 [==============================] - 32s 48ms/step - loss: 0.1902 - auc: 0.4985 - val_loss: 0.2174 - val_auc: 0.5000\n",
            "Epoch 14/30\n",
            "665/665 [==============================] - 33s 49ms/step - loss: 0.1902 - auc: 0.5000 - val_loss: 0.2214 - val_auc: 0.5000\n",
            "Epoch 15/30\n",
            "665/665 [==============================] - 31s 47ms/step - loss: 0.1902 - auc: 0.5000 - val_loss: 0.2199 - val_auc: 0.5000\n",
            "Epoch 16/30\n",
            "665/665 [==============================] - 33s 50ms/step - loss: 0.1902 - auc: 0.5000 - val_loss: 0.2167 - val_auc: 0.5000\n",
            "Epoch 17/30\n",
            "665/665 [==============================] - 34s 51ms/step - loss: 0.1902 - auc: 0.5000 - val_loss: 0.2216 - val_auc: 0.5000\n",
            "Epoch 18/30\n",
            "665/665 [==============================] - 32s 49ms/step - loss: 0.1902 - auc: 0.4868 - val_loss: 0.2183 - val_auc: 0.5000\n",
            "Epoch 19/30\n",
            "665/665 [==============================] - 35s 53ms/step - loss: 0.1902 - auc: 0.4981 - val_loss: 0.2303 - val_auc: 0.5000\n",
            "Epoch 20/30\n",
            "665/665 [==============================] - 34s 51ms/step - loss: 0.1902 - auc: 0.5000 - val_loss: 0.2166 - val_auc: 0.5000\n",
            "Epoch 21/30\n",
            "665/665 [==============================] - 32s 48ms/step - loss: 0.1902 - auc: 0.5000 - val_loss: 0.2126 - val_auc: 0.5000\n",
            "Epoch 22/30\n",
            "665/665 [==============================] - 33s 49ms/step - loss: 0.1902 - auc: 0.5000 - val_loss: 0.2305 - val_auc: 0.5000\n",
            "Epoch 23/30\n",
            "665/665 [==============================] - 34s 51ms/step - loss: 0.1902 - auc: 0.5000 - val_loss: 0.2078 - val_auc: 0.5000\n",
            "Epoch 24/30\n",
            "665/665 [==============================] - 33s 49ms/step - loss: 0.1902 - auc: 0.5000 - val_loss: 0.2312 - val_auc: 0.5000\n",
            "Epoch 25/30\n",
            "665/665 [==============================] - 33s 49ms/step - loss: 0.1902 - auc: 0.5000 - val_loss: 0.2279 - val_auc: 0.5000\n",
            "Epoch 26/30\n",
            "665/665 [==============================] - 32s 49ms/step - loss: 0.1902 - auc: 0.5000 - val_loss: 0.2005 - val_auc: 0.5000\n",
            "Epoch 27/30\n",
            "665/665 [==============================] - 36s 54ms/step - loss: 0.1902 - auc: 0.5000 - val_loss: 0.2166 - val_auc: 0.5000\n",
            "Epoch 28/30\n",
            "665/665 [==============================] - 36s 53ms/step - loss: 0.1902 - auc: 0.5000 - val_loss: 0.2222 - val_auc: 0.5000\n",
            "Epoch 29/30\n",
            "665/665 [==============================] - 35s 52ms/step - loss: 0.1902 - auc: 0.5000 - val_loss: 0.2287 - val_auc: 0.5000\n",
            "Epoch 30/30\n",
            "665/665 [==============================] - 34s 52ms/step - loss: 0.1902 - auc: 0.5000 - val_loss: 0.2231 - val_auc: 0.5000\n"
          ]
        }
      ],
      "source": [
        "#Train the model for 30 epochs using a custom data generator and batch size of 32\n",
        "\n",
        "import math\n",
        "\n",
        "batch_size = 32\n",
        "num_batchs = math.ceil(len(X) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(Y) / batch_size)\n",
        "\n",
        "history = model3.fit(\n",
        "    gen_batch(\n",
        "        X, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=30,\n",
        "    validation_data=gen_batch(\n",
        "        Y, batch_size=32, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e74eecf-39ef-4655-b03d-73553260c2bc",
        "id": "BluQ9czhMroE"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "771/771 [==============================] - 37s 46ms/step\n"
          ]
        }
      ],
      "source": [
        "# Use the model to make predictions on the test data\n",
        "# The test data is generated in batches of 32 and not shuffled\n",
        "y_pred3 = model3.predict(\n",
        "    gen_batch(test, batch_size=16, shuffle=False)\n",
        ")\n",
        "# Reshape the predictions to a one-dimensional array\n",
        "\n",
        "y_pred3 = np.reshape(y_pred3, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "340c82f9-8ce5-437e-ef12-8ac063255406",
        "id": "q-SbUD-4MroE"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12326"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "len(y_pred3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptlmumr-MroE"
      },
      "outputs": [],
      "source": [
        "#  (if for kaggle competition and it is about genre prediction)\n",
        "import pandas as pd \n",
        "submission = pd.DataFrame({'label':y_pred3})\n",
        "submission.index.name = 'id'\n",
        "submission.to_csv('sample_submission3.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This trail get score 0.5 on Kaggle "
      ],
      "metadata": {
        "id": "tBxxLax1MroF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`this is the worst trail i try it. it's seems the model doesn't learn well`"
      ],
      "metadata": {
        "id": "-t0Yw0cfaHYD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The fifth trail\n",
        "#GGNN \n",
        "* GGNN stands for Gated Graph Sequence Neural Network, which is a type of Graph Neural Network (GNN) that can process graph-structured data. GGNN uses gated recurrent units (GRUs) to update the node features iteratively, based on the features of their neighbors and edges. GGNN can learn to encode the graph structure and node attributes into a fixed-size vector representation, which can be used for various downstream tasks, such as graph classification, node classification, or graph generation.\n",
        "* We use GGNN in our code when we want to handle graph-structured inputs that may have variable size, shape, or connectivity. GGNN can capture the sequential and relational aspects of the graph data and learn complex patterns and dependencies among the nodes and edges. GGNN can also handle graphs with different types of edges or relations, by using different weight matrices for each edge type.\n",
        "* GGNN can achieve better performance and accuracy than other GNN models or traditional machine learning methods for anti-cancer activity prediction."
      ],
      "metadata": {
        "id": "_jB7OLKRpThV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`I expect this trail will be the best` (before Up sampling)"
      ],
      "metadata": {
        "id": "Ix-BN7l_av5z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "480007f5-233a-493e-d958-656f3237247b",
        "id": "TblwFi2fqmBb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ggnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='gnn_9/StatefulPartitionedCall:0', description=\"created by layer 'gnn_9'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='tf.math.segment_mean_5/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_5'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_5/Sigmoid:0', description=\"created by layer 'dense_5'\")\n",
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_36 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_34 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_10 (TFOpLam  ()                  0           ['input_36[0][0]']               \n",
            " bda)                                                                                             \n",
            "                                                                                                  \n",
            " embedding_11 (Embedding)       (None, 20)           10000       ['input_34[0][0]']               \n",
            "                                                                                                  \n",
            " input_35 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_10 (TFOpL  ()                  0           ['tf.math.reduce_max_10[0][0]']  \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " gnn_9 (GNN)                    (None, 64)           171392      ['embedding_11[0][0]',           \n",
            "                                                                  'input_35[0][0]',               \n",
            "                                                                  'input_36[0][0]',               \n",
            "                                                                  'tf.__operators__.add_10[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.segment_mean_5 (TFOpLa  (None, 64)          0           ['gnn_9[0][0]',                  \n",
            " mbda)                                                            'input_36[0][0]']               \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 1)            65          ['tf.math.segment_mean_5[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 181,457\n",
            "Trainable params: 181,457\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Define the input for the node features (a batch of sequences of tokens)\n",
        "data = Input(batch_shape=(None,))\n",
        "\n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "edge_index = Input(batch_shape=(None, 2),  dtype=tf.int32)\n",
        "node2graph = Input(batch_shape=(None,), dtype=tf.int32)\n",
        "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
        "\n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1\n",
        "\n",
        "# Define the RGCN layer\n",
        "ggnn_input = GNNInput( \n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge_index,),\n",
        "    node_to_graph_map=node2graph,\n",
        "    num_graphs=num_graph, \n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "#Get the default hyperparameters for the GNN model and set the hidden dimension to 64\n",
        "params4 = GNN.get_default_hyperparameters()\n",
        "params4[\"hidden_dim\"] = 64\n",
        "#Set the number of hidden layers for the aggregation MLP to 32\n",
        "params4[\"num_aggr_MLP_HIDDEN_LAYERS\"] = 32\n",
        "#Set the message calculation class to GGNN (Gated Graph Neural Network)\n",
        "params4['message_calculation_class']= 'GGNN'\n",
        "#Set the number of attention heads to 4\n",
        "params4['num_heads']= 4\n",
        "\n",
        "#Create a GNN layer with the given parameters\n",
        "ggnn_layer = GNN(params4)\n",
        "\n",
        "#Apply the GNN layer to the input and get the output node representations\n",
        "ggnn_out = ggnn_layer(ggnn_input)\n",
        "\n",
        "#Print the shape and values of ggnn_out\n",
        "print('ggnn_out', ggnn_out)\n",
        "\n",
        "#Compute the mean of the node representations for each graph using segment_mean\n",
        "avg = segment_mean(\n",
        "    data=ggnn_out,\n",
        "    segment_ids=node2graph\n",
        ")\n",
        "\n",
        "#Print the shape and values of avg\n",
        "print('mean:', avg)\n",
        "\n",
        "#Apply a dense layer with sigmoid activation to get the prediction for each graph\n",
        "pred4 = Dense(1, activation='sigmoid')(avg)\n",
        "print('pred:', pred4)\n",
        "\n",
        "#Define the model with inputs and outputs\n",
        "model4 = Model(\n",
        "    inputs={\n",
        "        'data': data,\n",
        "        'edges': edge_index,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs=pred4\n",
        ")\n",
        "model4.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-BFjqbXqmBe"
      },
      "outputs": [],
      "source": [
        "#Set up the model for binary classification with BinaryCrossentropy loss and AUC metric\n",
        "model4.compile(\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9b47c79-2a94-4b5a-c165-3881eae95ebf",
        "id": "weZELz9GqmBe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "665/665 [==============================] - 90s 126ms/step - loss: 0.1980 - auc: 0.5968 - val_loss: 0.1956 - val_auc: 0.6439\n",
            "Epoch 2/30\n",
            "665/665 [==============================] - 82s 124ms/step - loss: 0.1873 - auc: 0.6347 - val_loss: 0.1940 - val_auc: 0.6684\n",
            "Epoch 3/30\n",
            "665/665 [==============================] - 72s 108ms/step - loss: 0.1860 - auc: 0.6497 - val_loss: 0.1886 - val_auc: 0.6918\n",
            "Epoch 4/30\n",
            "665/665 [==============================] - 71s 107ms/step - loss: 0.1847 - auc: 0.6569 - val_loss: 0.1896 - val_auc: 0.7106\n",
            "Epoch 5/30\n",
            "665/665 [==============================] - 69s 104ms/step - loss: 0.1805 - auc: 0.6930 - val_loss: 0.1909 - val_auc: 0.7043\n",
            "Epoch 6/30\n",
            "665/665 [==============================] - 70s 106ms/step - loss: 0.1811 - auc: 0.6794 - val_loss: 0.1881 - val_auc: 0.7188\n",
            "Epoch 7/30\n",
            "665/665 [==============================] - 69s 104ms/step - loss: 0.1805 - auc: 0.6870 - val_loss: 0.1837 - val_auc: 0.7242\n",
            "Epoch 8/30\n",
            "665/665 [==============================] - 69s 104ms/step - loss: 0.1814 - auc: 0.6855 - val_loss: 0.1838 - val_auc: 0.7235\n",
            "Epoch 9/30\n",
            "665/665 [==============================] - 71s 107ms/step - loss: 0.1798 - auc: 0.6914 - val_loss: 0.1873 - val_auc: 0.7225\n",
            "Epoch 10/30\n",
            "665/665 [==============================] - 70s 105ms/step - loss: 0.1802 - auc: 0.6887 - val_loss: 0.1913 - val_auc: 0.6952\n",
            "Epoch 11/30\n",
            "665/665 [==============================] - 71s 107ms/step - loss: 0.1794 - auc: 0.6972 - val_loss: 0.1861 - val_auc: 0.7248\n",
            "Epoch 12/30\n",
            "665/665 [==============================] - 69s 104ms/step - loss: 0.1783 - auc: 0.7035 - val_loss: 0.1875 - val_auc: 0.7160\n",
            "Epoch 13/30\n",
            "665/665 [==============================] - 69s 104ms/step - loss: 0.1774 - auc: 0.7097 - val_loss: 0.1892 - val_auc: 0.7244\n",
            "Epoch 14/30\n",
            "665/665 [==============================] - 71s 107ms/step - loss: 0.1766 - auc: 0.7138 - val_loss: 0.1748 - val_auc: 0.7292\n",
            "Epoch 15/30\n",
            "665/665 [==============================] - 70s 105ms/step - loss: 0.1772 - auc: 0.7113 - val_loss: 0.1845 - val_auc: 0.7256\n",
            "Epoch 16/30\n",
            "665/665 [==============================] - 70s 106ms/step - loss: 0.1761 - auc: 0.7155 - val_loss: 0.1838 - val_auc: 0.7399\n",
            "Epoch 17/30\n",
            "665/665 [==============================] - 69s 104ms/step - loss: 0.1752 - auc: 0.7156 - val_loss: 0.1813 - val_auc: 0.7265\n",
            "Epoch 18/30\n",
            "665/665 [==============================] - 71s 106ms/step - loss: 0.1736 - auc: 0.7283 - val_loss: 0.1734 - val_auc: 0.7666\n",
            "Epoch 19/30\n",
            "665/665 [==============================] - 70s 105ms/step - loss: 0.1714 - auc: 0.7392 - val_loss: 0.1779 - val_auc: 0.7508\n",
            "Epoch 20/30\n",
            "665/665 [==============================] - 72s 108ms/step - loss: 0.1698 - auc: 0.7429 - val_loss: 0.1688 - val_auc: 0.7781\n",
            "Epoch 21/30\n",
            "665/665 [==============================] - 71s 107ms/step - loss: 0.1680 - auc: 0.7565 - val_loss: 0.1800 - val_auc: 0.7659\n",
            "Epoch 22/30\n",
            "665/665 [==============================] - 72s 108ms/step - loss: 0.1658 - auc: 0.7668 - val_loss: 0.1612 - val_auc: 0.7823\n",
            "Epoch 23/30\n",
            "665/665 [==============================] - 71s 108ms/step - loss: 0.1645 - auc: 0.7713 - val_loss: 0.1760 - val_auc: 0.7913\n",
            "Epoch 24/30\n",
            "665/665 [==============================] - 70s 105ms/step - loss: 0.1625 - auc: 0.7799 - val_loss: 0.1722 - val_auc: 0.7728\n",
            "Epoch 25/30\n",
            "665/665 [==============================] - 70s 106ms/step - loss: 0.1607 - auc: 0.7917 - val_loss: 0.1754 - val_auc: 0.8060\n",
            "Epoch 26/30\n",
            "665/665 [==============================] - 71s 108ms/step - loss: 0.1596 - auc: 0.7953 - val_loss: 0.1628 - val_auc: 0.8093\n",
            "Epoch 27/30\n",
            "665/665 [==============================] - 70s 106ms/step - loss: 0.1587 - auc: 0.7967 - val_loss: 0.1688 - val_auc: 0.8048\n",
            "Epoch 28/30\n",
            "665/665 [==============================] - 70s 105ms/step - loss: 0.1575 - auc: 0.8035 - val_loss: 0.1648 - val_auc: 0.8062\n",
            "Epoch 29/30\n",
            "665/665 [==============================] - 70s 105ms/step - loss: 0.1557 - auc: 0.8084 - val_loss: 0.1570 - val_auc: 0.8207\n",
            "Epoch 30/30\n",
            "665/665 [==============================] - 71s 106ms/step - loss: 0.1533 - auc: 0.8163 - val_loss: 0.1604 - val_auc: 0.8280\n"
          ]
        }
      ],
      "source": [
        "#Train the model for 30 epochs using a custom data generator and batch size of 32\n",
        "\n",
        "import math\n",
        "\n",
        "batch_size = 32\n",
        "num_batchs = math.ceil(len(X) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(Y) / batch_size)\n",
        "\n",
        "history = model4.fit(\n",
        "    gen_batch(\n",
        "        X, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=30,\n",
        "    validation_data=gen_batch(\n",
        "        Y, batch_size=32, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4b108fc-e6a0-4100-e928-98883584877f",
        "id": "RgCdtH2gqmBf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "386/386 [==============================] - 18s 46ms/step\n"
          ]
        }
      ],
      "source": [
        "# Use the model to make predictions on the test data\n",
        "# The test data is generated in batches of 32 and not shuffled\n",
        "y_pred4 = model4.predict(\n",
        "    gen_batch(test, batch_size=32, shuffle=False)\n",
        ")\n",
        "# Reshape the predictions to a one-dimensional array\n",
        "y_pred4 = np.reshape(y_pred4, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "191a354d-fa37-4c75-a82b-211fc086b499",
        "id": "t2k8SyxHqmBg"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12326"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "len(y_pred4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNWrwzaeqmBh"
      },
      "outputs": [],
      "source": [
        "#  (if for kaggle competition and it is about genre prediction)\n",
        "import pandas as pd \n",
        "submission = pd.DataFrame({'label':y_pred4})\n",
        "submission.index.name = 'id'\n",
        "submission.to_csv('sample_submission4.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This trail get score 0.83686 on Kaggle "
      ],
      "metadata": {
        "id": "_mnWfmfZ0LhJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`As I expected, the performance of this trail is the best :)` (before up sampling)\n"
      ],
      "metadata": {
        "id": "jWixTqE3bYBa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###We are aware of the data's imbalance.\n",
        "### SO, we need to reprocess the data.\n"
      ],
      "metadata": {
        "id": "23iAefGjfpLE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Up sampling\n",
        "up sampling is a way to balance the data when there is a class imbalance problem. It means creating more samples of the minority class by randomly duplicating existing samples or generating new samples based on existing ones. This can help improve the performance of machine learning models that are trained on the balanced data."
      ],
      "metadata": {
        "id": "4HlYTTt2gT0U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the pandas library as pd\n",
        "import pandas as pd\n",
        "# Create a data frame from the train data\n",
        "# The data frame has three columns: nodes, edge, and label\n",
        "train_set=pd.DataFrame(train,columns=['nodes','edge','label'])\n",
        "# Display the data frame\n",
        "train_set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "IUuzgelbgexS",
        "outputId": "a9011084-7421-4cff-ccef-b4c997bf12ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   nodes  \\\n",
              "0      [S, O, O, O, O, N, N, N, C, C, C, C, C, C, C, ...   \n",
              "1      [O, O, O, O, O, O, N, N, N, C, C, C, C, C, C, ...   \n",
              "2      [F, F, F, O, O, O, O, O, N, N, C, C, C, C, C, ...   \n",
              "3      [Cl, S, S, O, O, O, O, N, N, N, N, C, C, C, C,...   \n",
              "4      [S, O, O, N, N, N, N, N, N, C, C, C, C, C, C, ...   \n",
              "...                                                  ...   \n",
              "25019  [O, O, O, O, O, O, N, N, C, C, C, C, C, C, C, ...   \n",
              "25020  [O, O, O, O, O, N, C, C, C, C, C, C, C, C, C, ...   \n",
              "25021  [O, O, O, O, O, O, O, O, O, N, C, C, C, C, C, ...   \n",
              "25022  [S, O, O, O, O, N, N, N, C, C, C, C, C, C, C, ...   \n",
              "25023  [Cl, Cl, Cl, S, O, O, O, O, N, N, N, N, N, C, ...   \n",
              "\n",
              "                                                    edge  label  \n",
              "0      [[0, 8], [0, 14], [1, 10], [2, 11], [3, 7], [4...      0  \n",
              "1      [[0, 6], [0, 15], [1, 15], [2, 7], [3, 8], [4,...      0  \n",
              "2      [[0, 19], [1, 19], [2, 19], [3, 16], [4, 28], ...      0  \n",
              "3      [[0, 12], [1, 15], [1, 18], [2, 4], [2, 5], [2...      0  \n",
              "4      [[0, 1], [0, 2], [0, 5], [0, 9], [3, 4], [3, 1...      0  \n",
              "...                                                  ...    ...  \n",
              "25019  [[0, 8], [0, 14], [1, 10], [2, 12], [3, 13], [...      0  \n",
              "25020  [[0, 9], [1, 11], [2, 16], [2, 19], [3, 16], [...      0  \n",
              "25021  [[0, 12], [0, 16], [1, 10], [2, 11], [3, 15], ...      0  \n",
              "25022  [[0, 11], [0, 12], [1, 21], [1, 27], [2, 22], ...      0  \n",
              "25023  [[0, 25], [1, 26], [2, 29], [3, 13], [3, 15], ...      0  \n",
              "\n",
              "[25024 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f4a8b1fa-5df9-44e8-aca2-a8277350d9c6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nodes</th>\n",
              "      <th>edge</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[S, O, O, O, O, N, N, N, C, C, C, C, C, C, C, ...</td>\n",
              "      <td>[[0, 8], [0, 14], [1, 10], [2, 11], [3, 7], [4...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[O, O, O, O, O, O, N, N, N, C, C, C, C, C, C, ...</td>\n",
              "      <td>[[0, 6], [0, 15], [1, 15], [2, 7], [3, 8], [4,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[F, F, F, O, O, O, O, O, N, N, C, C, C, C, C, ...</td>\n",
              "      <td>[[0, 19], [1, 19], [2, 19], [3, 16], [4, 28], ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[Cl, S, S, O, O, O, O, N, N, N, N, C, C, C, C,...</td>\n",
              "      <td>[[0, 12], [1, 15], [1, 18], [2, 4], [2, 5], [2...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[S, O, O, N, N, N, N, N, N, C, C, C, C, C, C, ...</td>\n",
              "      <td>[[0, 1], [0, 2], [0, 5], [0, 9], [3, 4], [3, 1...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25019</th>\n",
              "      <td>[O, O, O, O, O, O, N, N, C, C, C, C, C, C, C, ...</td>\n",
              "      <td>[[0, 8], [0, 14], [1, 10], [2, 12], [3, 13], [...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25020</th>\n",
              "      <td>[O, O, O, O, O, N, C, C, C, C, C, C, C, C, C, ...</td>\n",
              "      <td>[[0, 9], [1, 11], [2, 16], [2, 19], [3, 16], [...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25021</th>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, N, C, C, C, C, C, ...</td>\n",
              "      <td>[[0, 12], [0, 16], [1, 10], [2, 11], [3, 15], ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25022</th>\n",
              "      <td>[S, O, O, O, O, N, N, N, C, C, C, C, C, C, C, ...</td>\n",
              "      <td>[[0, 11], [0, 12], [1, 21], [1, 27], [2, 22], ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25023</th>\n",
              "      <td>[Cl, Cl, Cl, S, O, O, O, O, N, N, N, N, N, C, ...</td>\n",
              "      <td>[[0, 25], [1, 26], [2, 29], [3, 13], [3, 15], ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25024 rows √ó 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4a8b1fa-5df9-44e8-aca2-a8277350d9c6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f4a8b1fa-5df9-44e8-aca2-a8277350d9c6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f4a8b1fa-5df9-44e8-aca2-a8277350d9c6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new data frame for each class label\n",
        "# class0 contains only the rows where label is 0\n",
        "# class1 contains only the rows where label is 1 \n",
        "class0=train_set[train_set['label']==0]\n",
        "class1=train_set[train_set['label']==1]"
      ],
      "metadata": {
        "id": "bjNBs83KghyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the resample function from sklearn.utils\n",
        "from sklearn.utils import resample\n",
        "# Create a new data frame for class 1 by sampling with replacement\n",
        "# The number of samples is equal to the number of rows in class 0\n",
        "# The random state is set to 42 for reproducibility\n",
        "Sclass1 = resample(class1, replace=True, n_samples=len(class0), random_state=42)\n",
        "# Display the new data frame\n",
        "Sclass1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "150Y41qZiI58",
        "outputId": "26e29906-f430-49b6-8bd1-2888a65e1717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   nodes  \\\n",
              "23357  [O, O, O, O, O, C, C, C, C, C, C, C, C, C, C, ...   \n",
              "17640  [O, O, O, O, O, O, O, C, C, C, C, C, C, C, C, ...   \n",
              "23463  [O, O, N, N, C, C, C, C, C, C, C, C, C, C, C, ...   \n",
              "22676  [O, O, O, O, O, O, O, C, C, C, C, C, C, C, C, ...   \n",
              "21324  [S, S, O, O, O, O, N, N, C, C, C, C, C, C, C, ...   \n",
              "...                                                  ...   \n",
              "16643  [O, O, O, O, O, O, N, C, C, C, C, C, C, C, C, ...   \n",
              "5670   [Cl, O, O, O, O, O, O, O, O, N, N, N, N, C, C,...   \n",
              "4221   [Cl, Cl, O, O, O, O, N, N, N, C, C, C, C, C, C...   \n",
              "14241  [Cl, O, O, O, O, O, O, O, O, O, O, C, C, C, C,...   \n",
              "19722               [O, O, O, O, N, N, N, C, C, C, C, C]   \n",
              "\n",
              "                                                    edge  label  \n",
              "23357  [[8, 0], [0, 19], [1, 17], [1, 22], [2, 19], [...      1  \n",
              "17640  [[7, 0], [8, 0], [1, 14], [1, 15], [11, 2], [1...      1  \n",
              "23463  [[0, 5], [1, 4], [2, 4], [2, 5], [2, 6], [3, 4...      1  \n",
              "22676  [[0, 9], [0, 11], [1, 9], [1, 19], [2, 10], [2...      1  \n",
              "21324  [[0, 8], [0, 13], [1, 11], [1, 12], [16, 2], [...      1  \n",
              "...                                                  ...    ...  \n",
              "16643  [[0, 9], [0, 24], [1, 12], [1, 25], [2, 14], [...      1  \n",
              "5670   [[0, 32], [1, 17], [2, 25], [2, 36], [3, 27], ...      1  \n",
              "4221   [[0, 30], [1, 31], [2, 15], [2, 27], [3, 13], ...      1  \n",
              "14241  [[30, 0], [11, 1], [14, 1], [2, 13], [2, 22], ...      1  \n",
              "19722  [[0, 8], [0, 9], [1, 8], [2, 10], [3, 10], [4,...      1  \n",
              "\n",
              "[23806 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-31e7001c-4169-4faf-9bd7-192c78caa131\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nodes</th>\n",
              "      <th>edge</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>23357</th>\n",
              "      <td>[O, O, O, O, O, C, C, C, C, C, C, C, C, C, C, ...</td>\n",
              "      <td>[[8, 0], [0, 19], [1, 17], [1, 22], [2, 19], [...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17640</th>\n",
              "      <td>[O, O, O, O, O, O, O, C, C, C, C, C, C, C, C, ...</td>\n",
              "      <td>[[7, 0], [8, 0], [1, 14], [1, 15], [11, 2], [1...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23463</th>\n",
              "      <td>[O, O, N, N, C, C, C, C, C, C, C, C, C, C, C, ...</td>\n",
              "      <td>[[0, 5], [1, 4], [2, 4], [2, 5], [2, 6], [3, 4...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22676</th>\n",
              "      <td>[O, O, O, O, O, O, O, C, C, C, C, C, C, C, C, ...</td>\n",
              "      <td>[[0, 9], [0, 11], [1, 9], [1, 19], [2, 10], [2...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21324</th>\n",
              "      <td>[S, S, O, O, O, O, N, N, C, C, C, C, C, C, C, ...</td>\n",
              "      <td>[[0, 8], [0, 13], [1, 11], [1, 12], [16, 2], [...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16643</th>\n",
              "      <td>[O, O, O, O, O, O, N, C, C, C, C, C, C, C, C, ...</td>\n",
              "      <td>[[0, 9], [0, 24], [1, 12], [1, 25], [2, 14], [...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5670</th>\n",
              "      <td>[Cl, O, O, O, O, O, O, O, O, N, N, N, N, C, C,...</td>\n",
              "      <td>[[0, 32], [1, 17], [2, 25], [2, 36], [3, 27], ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4221</th>\n",
              "      <td>[Cl, Cl, O, O, O, O, N, N, N, C, C, C, C, C, C...</td>\n",
              "      <td>[[0, 30], [1, 31], [2, 15], [2, 27], [3, 13], ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14241</th>\n",
              "      <td>[Cl, O, O, O, O, O, O, O, O, O, O, C, C, C, C,...</td>\n",
              "      <td>[[30, 0], [11, 1], [14, 1], [2, 13], [2, 22], ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19722</th>\n",
              "      <td>[O, O, O, O, N, N, N, C, C, C, C, C]</td>\n",
              "      <td>[[0, 8], [0, 9], [1, 8], [2, 10], [3, 10], [4,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>23806 rows √ó 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-31e7001c-4169-4faf-9bd7-192c78caa131')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-31e7001c-4169-4faf-9bd7-192c78caa131 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-31e7001c-4169-4faf-9bd7-192c78caa131');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new data frame by concatenating class0 and Sclass1\n",
        "# The new data frame has balanced classes\n",
        "New_train = pd.concat([class0,Sclass1])"
      ],
      "metadata": {
        "id": "Ao-pzzyliMo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of rows for each class label in the new data frame\n",
        "# The result should show that both classes have the same count\n",
        "New_train['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnYQJylMi5By",
        "outputId": "4d752308-2e25-48d8-f6e3-4a5b623c299c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    23806\n",
              "1    23806\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the new data frame to a numpy array\n",
        "# This is useful for applying machine learning algorithms\n",
        "New_train = New_train.to_numpy()"
      ],
      "metadata": {
        "id": "FzlBUy05jDp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spilt New Train set to train and vaildation set"
      ],
      "metadata": {
        "id": "6ZJZ9LkQjK8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#spilt train set to train and vaildation set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x, y = train_test_split( New_train , test_size=0.2)\n"
      ],
      "metadata": {
        "id": "5h7a_2PvjJHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "-9RMgJ0Bin7Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Toknization\n",
        "\n",
        "Tokenization is an important step in text preprocessing that can help facilitate downstream NLP tasks."
      ],
      "metadata": {
        "id": "-Xo729NLkF87"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65w9Rap4kF9T"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "max_vocab = 500\n",
        "max_len = 100\n",
        "\n",
        "\n",
        "# build vocabulary from training set\n",
        "all_nodes = [s[0] for s in x]\n",
        "tokenizer = Tokenizer(num_words=max_vocab)\n",
        "tokenizer.fit_on_texts(all_nodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1jOc7E4kF9T"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import random\n",
        "random.seed(0)\n",
        "\n",
        "def prepare_single_batch(samples):\n",
        "    sample_nodes = [s[0] for s in samples]\n",
        "    sample_nodes = tokenizer.texts_to_sequences(sample_nodes)\n",
        "    sample_nodes = pad_sequences(sample_nodes, padding='post')\n",
        "    max_nodes_len = np.shape(sample_nodes)[1]\n",
        "    edges = [s[1]+i*max_nodes_len for i,s in enumerate(samples)]\n",
        "    edges = [e for e in edges if len(e) > 0]\n",
        "    node_to_graph = [[i]*max_nodes_len for i in range(len(samples))]\n",
        "    \n",
        "    all_nodes = np.reshape(sample_nodes, -1)\n",
        "    all_edges = np.concatenate(edges)\n",
        "\n",
        "    node_to_graph = np.reshape(node_to_graph, -1)\n",
        "    return {\n",
        "        'data': all_nodes,\n",
        "        'edges': all_edges,\n",
        "        'node2grah': node_to_graph,\n",
        "    }, np.array([s[2] for s in samples])\n",
        "\n",
        "\n",
        "\n",
        "def gen_batch(dataset, batch_size=16, repeat=False, shuffle=True):\n",
        "    while True:\n",
        "        dataset = list(dataset)\n",
        "        if shuffle:\n",
        "            random.shuffle(dataset)\n",
        "        l = len(dataset)\n",
        "        for ndx in range(0, l, batch_size):\n",
        "            batch_samples = dataset[ndx:min(ndx + batch_size, l)]\n",
        "            yield prepare_single_batch(batch_samples)\n",
        "        if not repeat:\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58ecc81d-9d25-4102-fc4c-2f0946f2414d",
        "id": "ALBYY1IkkF9U"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data\n",
            "[2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 3 3 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "edges\n",
            "[[  0   6]\n",
            " [  1   8]\n",
            " [  2   3]\n",
            " [  2   5]\n",
            " [  2   6]\n",
            " [  3   4]\n",
            " [  3  13]\n",
            " [  4   7]\n",
            " [  4  11]\n",
            " [  5  10]\n",
            " [  5  12]\n",
            " [  6   8]\n",
            " [  7  14]\n",
            " [  7  17]\n",
            " [  7  18]\n",
            " [  8   9]\n",
            " [  9  10]\n",
            " [  9  16]\n",
            " [ 11  12]\n",
            " [ 13  15]\n",
            " [ 14  15]\n",
            " [ 16  19]\n",
            " [ 16  20]\n",
            " [ 64  70]\n",
            " [ 64  71]\n",
            " [ 65  68]\n",
            " [ 65  72]\n",
            " [ 66  78]\n",
            " [ 67  81]\n",
            " [ 68  69]\n",
            " [ 68  70]\n",
            " [ 69  71]\n",
            " [ 69  75]\n",
            " [ 70  74]\n",
            " [ 71  76]\n",
            " [ 72  73]\n",
            " [ 72  77]\n",
            " [ 73  74]\n",
            " [ 73  79]\n",
            " [ 75  80]\n",
            " [ 76  78]\n",
            " [ 77  81]\n",
            " [ 78  80]\n",
            " [ 79  82]\n",
            " [ 81  82]\n",
            " [128 144]\n",
            " [148 128]\n",
            " [129 143]\n",
            " [129 150]\n",
            " [130 148]\n",
            " [130 156]\n",
            " [143 131]\n",
            " [132 147]\n",
            " [132 159]\n",
            " [133 159]\n",
            " [166 134]\n",
            " [168 135]\n",
            " [172 136]\n",
            " [136 179]\n",
            " [169 137]\n",
            " [173 138]\n",
            " [175 139]\n",
            " [140 179]\n",
            " [140 185]\n",
            " [176 141]\n",
            " [142 186]\n",
            " [142 190]\n",
            " [142 191]\n",
            " [143 145]\n",
            " [143 149]\n",
            " [144 146]\n",
            " [144 149]\n",
            " [145 152]\n",
            " [145 153]\n",
            " [146 147]\n",
            " [146 155]\n",
            " [147 151]\n",
            " [148 151]\n",
            " [148 154]\n",
            " [150 152]\n",
            " [150 157]\n",
            " [150 158]\n",
            " [153 161]\n",
            " [154 160]\n",
            " [156 162]\n",
            " [156 163]\n",
            " [159 164]\n",
            " [160 162]\n",
            " [161 165]\n",
            " [163 166]\n",
            " [164 167]\n",
            " [165 170]\n",
            " [166 174]\n",
            " [167 168]\n",
            " [168 169]\n",
            " [168 177]\n",
            " [169 171]\n",
            " [170 178]\n",
            " [171 173]\n",
            " [171 182]\n",
            " [172 173]\n",
            " [172 175]\n",
            " [174 183]\n",
            " [175 176]\n",
            " [176 180]\n",
            " [176 184]\n",
            " [178 181]\n",
            " [179 187]\n",
            " [180 181]\n",
            " [185 186]\n",
            " [185 189]\n",
            " [186 188]\n",
            " [187 188]\n",
            " [192 205]\n",
            " [193 206]\n",
            " [194 207]\n",
            " [195 196]\n",
            " [195 197]\n",
            " [195 198]\n",
            " [196 199]\n",
            " [196 200]\n",
            " [197 201]\n",
            " [197 203]\n",
            " [198 202]\n",
            " [198 204]\n",
            " [199 205]\n",
            " [199 208]\n",
            " [200 206]\n",
            " [200 209]\n",
            " [201 205]\n",
            " [201 211]\n",
            " [202 206]\n",
            " [202 212]\n",
            " [203 207]\n",
            " [203 213]\n",
            " [204 207]\n",
            " [204 214]\n",
            " [208 210]\n",
            " [209 210]\n",
            " [210 215]\n",
            " [211 216]\n",
            " [212 217]\n",
            " [213 216]\n",
            " [214 217]\n",
            " [215 218]\n",
            " [215 219]\n",
            " [215 220]]\n",
            "node2grah\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
            "label [0 1 1 0]\n"
          ]
        }
      ],
      "source": [
        "# showing one batch:\n",
        "for train_batch in gen_batch(x, batch_size=4):\n",
        "    for k,v in train_batch[0].items():\n",
        "        print(k)\n",
        "        print(v)\n",
        "        pass\n",
        "    print('label', train_batch[1])\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The Sixth trail\n",
        "#GGNN after Resampleing\n",
        "* GGNN stands for Gated Graph Sequence Neural Network, which is a type of Graph Neural Network (GNN) that can process graph-structured data. GGNN uses gated recurrent units (GRUs) to update the node features iteratively, based on the features of their neighbors and edges. GGNN can learn to encode the graph structure and node attributes into a fixed-size vector representation, which can be used for various downstream tasks, such as graph classification, node classification, or graph generation.\n",
        "* We use GGNN in our code when we want to handle graph-structured inputs that may have variable size, shape, or connectivity. GGNN can capture the sequential and relational aspects of the graph data and learn complex patterns and dependencies among the nodes and edges. GGNN can also handle graphs with different types of edges or relations, by using different weight matrices for each edge type.\n",
        "* GGNN can achieve better performance and accuracy than other GNN models or traditional machine learning methods for anti-cancer activity prediction."
      ],
      "metadata": {
        "id": "1m4fZ0S4kqsI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`I expect this trail will be the best`\n"
      ],
      "metadata": {
        "id": "lE30c6Z4cLaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.math import segment_mean\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import Embedding, Dense\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "GBZCHPyC0nZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b2d236e-314f-42b9-c31c-56c93f8f319e",
        "id": "4DNKW9JmkqsK"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ggnn_out2 KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='gnn/StatefulPartitionedCall:0', description=\"created by layer 'gnn'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='tf.math.segment_mean/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense/Sigmoid:0', description=\"created by layer 'dense'\")\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_1 (TFOpLamb  ()                  0           ['input_6[0][0]']                \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 20)           10000       ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " input_5 (InputLayer)           [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_1 (TFOpLa  ()                  0           ['tf.math.reduce_max_1[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn (GNN)                      (None, 64)           603008      ['embedding_1[0][0]',            \n",
            "                                                                  'input_5[0][0]',                \n",
            "                                                                  'input_6[0][0]',                \n",
            "                                                                  'tf.__operators__.add_1[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean (TFOpLamb  (None, 64)          0           ['gnn[0][0]',                    \n",
            " da)                                                              'input_6[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1)            65          ['tf.math.segment_mean[0][0]']   \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 613,073\n",
            "Trainable params: 613,073\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Define the input for the node features (a batch of sequences of tokens)\n",
        "data = Input(batch_shape=(None,))\n",
        "\n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "edge_index = Input(batch_shape=(None, 2),  dtype=tf.int32)\n",
        "node2graph = Input(batch_shape=(None,), dtype=tf.int32)\n",
        "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
        "\n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1\n",
        "\n",
        "# Define the RGCN layer\n",
        "ggnn_input2 = GNNInput( \n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge_index,),\n",
        "    node_to_graph_map=node2graph,\n",
        "    num_graphs=num_graph, \n",
        ")\n",
        "\n",
        "#Get the default hyperparameters for the GNN model and set the hidden dimension to 64\n",
        "params5 = GNN.get_default_hyperparameters()\n",
        "params5[\"hidden_dim\"] = 64\n",
        "#Set the number of hidden layers for the aggregation MLP to 32\n",
        "params5[\"num_aggr_MLP_HIDDEN_LAYERS\"] = 32\n",
        "#Set the message calculation class to GGNN (Gated Graph Neural Network)\n",
        "params5['message_calculation_class']= 'GGNN'\n",
        "#Set the number of attention heads to 4\n",
        "params5['num_heads']= 4\n",
        "#Create a GNN layer with the given parameters\n",
        "ggnn_layer2 = GNN(params5)\n",
        "#Apply the GNN layer to the input and get the output node representations\n",
        "ggnn_out2 = ggnn_layer2(ggnn_input2)\n",
        "#Print the shape and values of ggnn_out2\n",
        "print('ggnn_out2', ggnn_out2)\n",
        "\n",
        "#Compute the mean of the node representations for each graph using segment_mean\n",
        "avg = segment_mean(\n",
        "    data=ggnn_out2,\n",
        "    segment_ids=node2graph\n",
        ")\n",
        "#Print the shape and values of avg\n",
        "print('mean:', avg)\n",
        "\n",
        "#Apply a dense layer with sigmoid activation to get the prediction for each graph\n",
        "pred5 = Dense(1, activation='sigmoid')(avg)\n",
        "print('pred:', pred5)\n",
        "\n",
        "#Define the model with inputs and outputs\n",
        "model5 = Model(\n",
        "    inputs={\n",
        "        'data': data,\n",
        "        'edges': edge_index,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs=pred5\n",
        ")\n",
        "model5.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5WQgAWDkqsM"
      },
      "outputs": [],
      "source": [
        "#Set up the model for binary classification with BinaryCrossentropy loss and AUC metric\n",
        "model5.compile(\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "606906a9-fb73-4a0d-b521-f3af52b479d9",
        "id": "7fQVYxVlkqsM"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1270/1270 [==============================] - 86s 68ms/step - loss: 0.1481 - auc: 0.9844 - val_loss: 0.3163 - val_auc: 0.9632\n",
            "Epoch 2/30\n",
            "1270/1270 [==============================] - 98s 77ms/step - loss: 0.1529 - auc: 0.9833 - val_loss: 0.3828 - val_auc: 0.9598\n",
            "Epoch 3/30\n",
            "1270/1270 [==============================] - 90s 71ms/step - loss: 0.1574 - auc: 0.9825 - val_loss: 0.3367 - val_auc: 0.9643\n",
            "Epoch 4/30\n",
            "1270/1270 [==============================] - 90s 71ms/step - loss: 0.1540 - auc: 0.9835 - val_loss: 0.3229 - val_auc: 0.9655\n",
            "Epoch 5/30\n",
            "1270/1270 [==============================] - 82s 65ms/step - loss: 0.1528 - auc: 0.9834 - val_loss: 0.3827 - val_auc: 0.9620\n",
            "Epoch 6/30\n",
            "1270/1270 [==============================] - 79s 62ms/step - loss: 0.1449 - auc: 0.9847 - val_loss: 0.3863 - val_auc: 0.9662\n",
            "Epoch 7/30\n",
            "1270/1270 [==============================] - 90s 71ms/step - loss: 0.1451 - auc: 0.9846 - val_loss: 0.4115 - val_auc: 0.9595\n",
            "Epoch 8/30\n",
            "1270/1270 [==============================] - 88s 70ms/step - loss: 0.1452 - auc: 0.9845 - val_loss: 0.4204 - val_auc: 0.9597\n",
            "Epoch 9/30\n",
            "1270/1270 [==============================] - 80s 63ms/step - loss: 0.1376 - auc: 0.9857 - val_loss: 0.4124 - val_auc: 0.9619\n",
            "Epoch 10/30\n",
            "1270/1270 [==============================] - 83s 65ms/step - loss: 0.1380 - auc: 0.9856 - val_loss: 0.3074 - val_auc: 0.9684\n",
            "Epoch 11/30\n",
            "1270/1270 [==============================] - 83s 65ms/step - loss: 0.1383 - auc: 0.9856 - val_loss: 0.3398 - val_auc: 0.9636\n",
            "Epoch 12/30\n",
            "1270/1270 [==============================] - 85s 67ms/step - loss: 0.1350 - auc: 0.9865 - val_loss: 0.4593 - val_auc: 0.9594\n",
            "Epoch 13/30\n",
            "1270/1270 [==============================] - 73s 57ms/step - loss: 0.1365 - auc: 0.9862 - val_loss: 0.3156 - val_auc: 0.9694\n",
            "Epoch 14/30\n",
            "1270/1270 [==============================] - 77s 61ms/step - loss: 0.1362 - auc: 0.9862 - val_loss: 0.3463 - val_auc: 0.9677\n",
            "Epoch 15/30\n",
            "1270/1270 [==============================] - 75s 59ms/step - loss: 0.1394 - auc: 0.9861 - val_loss: 0.3322 - val_auc: 0.9669\n",
            "Epoch 16/30\n",
            "1270/1270 [==============================] - 82s 65ms/step - loss: 0.1260 - auc: 0.9878 - val_loss: 0.3348 - val_auc: 0.9654\n",
            "Epoch 17/30\n",
            "1270/1270 [==============================] - 88s 69ms/step - loss: 0.1275 - auc: 0.9872 - val_loss: 0.3423 - val_auc: 0.9636\n",
            "Epoch 18/30\n",
            "1270/1270 [==============================] - 74s 58ms/step - loss: 0.1243 - auc: 0.9881 - val_loss: 0.3544 - val_auc: 0.9664\n",
            "Epoch 19/30\n",
            "1270/1270 [==============================] - 86s 68ms/step - loss: 0.1236 - auc: 0.9880 - val_loss: 0.4413 - val_auc: 0.9609\n",
            "Epoch 20/30\n",
            "1270/1270 [==============================] - 77s 61ms/step - loss: 0.1209 - auc: 0.9882 - val_loss: 0.4088 - val_auc: 0.9610\n",
            "Epoch 21/30\n",
            "1270/1270 [==============================] - 77s 61ms/step - loss: 0.1183 - auc: 0.9889 - val_loss: 0.4024 - val_auc: 0.9616\n",
            "Epoch 22/30\n",
            "1270/1270 [==============================] - 78s 62ms/step - loss: 0.1215 - auc: 0.9885 - val_loss: 0.3141 - val_auc: 0.9687\n",
            "Epoch 23/30\n",
            "1270/1270 [==============================] - 62s 49ms/step - loss: 0.1164 - auc: 0.9893 - val_loss: 0.3223 - val_auc: 0.9713\n",
            "Epoch 24/30\n",
            "1270/1270 [==============================] - 62s 49ms/step - loss: 0.1201 - auc: 0.9886 - val_loss: 0.4162 - val_auc: 0.9636\n",
            "Epoch 25/30\n",
            "1270/1270 [==============================] - 63s 50ms/step - loss: 0.1648 - auc: 0.9815 - val_loss: 0.3227 - val_auc: 0.9669\n",
            "Epoch 26/30\n",
            "1270/1270 [==============================] - 78s 61ms/step - loss: 0.1166 - auc: 0.9890 - val_loss: 0.3523 - val_auc: 0.9648\n",
            "Epoch 27/30\n",
            "1270/1270 [==============================] - 75s 59ms/step - loss: 0.1143 - auc: 0.9895 - val_loss: 0.4405 - val_auc: 0.9615\n",
            "Epoch 28/30\n",
            "1270/1270 [==============================] - 66s 52ms/step - loss: 0.1208 - auc: 0.9882 - val_loss: 0.4066 - val_auc: 0.9629\n",
            "Epoch 29/30\n",
            "1270/1270 [==============================] - 84s 66ms/step - loss: 0.1126 - auc: 0.9899 - val_loss: 0.3979 - val_auc: 0.9656\n",
            "Epoch 30/30\n",
            "1270/1270 [==============================] - 84s 66ms/step - loss: 0.1116 - auc: 0.9898 - val_loss: 0.4320 - val_auc: 0.9609\n"
          ]
        }
      ],
      "source": [
        "#Train the model for 30 epochs using a custom data generator and batch size of 30\n",
        "\n",
        "import math\n",
        "\n",
        "batch_size = 30\n",
        "num_batchs = math.ceil(len(x) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(y) / batch_size)\n",
        "\n",
        "history = model5.fit(\n",
        "    gen_batch(\n",
        "        x, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=30,\n",
        "    validation_data=gen_batch(\n",
        "        y, batch_size=30, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75143091-3bca-4063-f7e2-a8b63d3020fa",
        "id": "lcHk6lFNkqsO"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "411/411 [==============================] - 5s 13ms/step\n"
          ]
        }
      ],
      "source": [
        "# Use the model to make predictions on the test data\n",
        "# The test data is generated in batches of 16 and not shuffled\n",
        "y_pred5 = model5.predict(\n",
        "    gen_batch(test, batch_size=16, shuffle=False)\n",
        ")\n",
        "# Reshape the predictions to a one-dimensional array\n",
        "y_pred5 = np.reshape(y_pred5, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e38208a8-1c8d-4f81-b46d-d95da8b6621d",
        "id": "-N61DTCfkqsP"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12326"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "len(y_pred5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "qgBJE1B3kqsQ"
      },
      "outputs": [],
      "source": [
        "#  (if for kaggle competition and it is about genre prediction)\n",
        "import pandas as pd \n",
        "submission = pd.DataFrame({'label':y_pred5})\n",
        "submission.index.name = 'id'\n",
        "submission.to_csv('sample_submission5.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This trail get Score: 0.85219 on kaggle"
      ],
      "metadata": {
        "id": "a2YIc6x1oFv5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `As I expected, the performance of this trail is the best :)` \n",
        "* After Up sampling ,The performance has improved\n",
        "\n"
      ],
      "metadata": {
        "id": "nD3V2OzJcp9Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Seventh trail\n",
        "# RGAT after resampling\n",
        "\n",
        "\n",
        "*   The Relational Graph Attention Network (RGAT) is a type of graph neural network (GNN) that is used for processing relationships between entities in a graph. \n",
        "\n",
        "*   RGATs are specifically designed to address the limitations of previous GNNs, such as the Graph Convolutional Network (GCN), which only consider a fixed edge weight for all nodes. RGATs model the relationships between pairs of nodes as edge weights and then use attention mechanisms to weigh these relationships, allowing the network to learn which relationships are most important for a given task.\n",
        "\n",
        "*   The main advantages of using RGAT over other GNNs include:\n",
        "\n",
        "      * Improved ability to capture complex dependencies in the graph\n",
        "\n",
        "      * Improved interpretability of the learned representation\n",
        "\n",
        "      * Improved performance on tasks that require reasoning about relationships between nodes\n",
        "*   Relational Graph Attention Network (RGAT) can be used for anti-cancer activity prediction by modeling relationships between entities such as molecular structures and biological activity using a graph. The RGAT architecture can learn to weigh relationships between entities, allowing it to capture complex dependencies in the graph and identify the most important relationships for predicting anti-cancer activity.\n",
        "*   RGAT could be a powerful tool for anti-cancer activity prediction, especially when the dependencies between molecular structures are complex and difficult to capture with traditional machine learning techniques.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PoJ7SpgJm1Af"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I expect the performance will be better than the previous RGAT trail before UP sampling.\n",
        "SO, let's try it"
      ],
      "metadata": {
        "id": "sBT2h6x3w_JG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cad16380-b766-47ff-fc59-f9400342c37f",
        "id": "etu47gWRm1Af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rgan_out KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='gnn_3/StatefulPartitionedCall:0', description=\"created by layer 'gnn_3'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='tf.math.segment_mean_3/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_3'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_3/Sigmoid:0', description=\"created by layer 'dense_3'\")\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_12 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_10 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_3 (TFOpLamb  ()                  0           ['input_12[0][0]']               \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)        (None, 20)           10000       ['input_10[0][0]']               \n",
            "                                                                                                  \n",
            " input_11 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_3 (TFOpLa  ()                  0           ['tf.math.reduce_max_3[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_3 (GNN)                    (None, 64)           72064       ['embedding_3[0][0]',            \n",
            "                                                                  'input_11[0][0]',               \n",
            "                                                                  'input_12[0][0]',               \n",
            "                                                                  'tf.__operators__.add_3[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_3 (TFOpLa  (None, 64)          0           ['gnn_3[0][0]',                  \n",
            " mbda)                                                            'input_12[0][0]']               \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 1)            65          ['tf.math.segment_mean_3[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 82,129\n",
            "Trainable params: 82,129\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Define the input for the node features (a batch of sequences of tokens)\n",
        "data = Input(batch_shape=(None,))\n",
        "\n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "edge_index = Input(batch_shape=(None, 2),  dtype=tf.int32)\n",
        "node2graph = Input(batch_shape=(None,), dtype=tf.int32)\n",
        "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
        "\n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1\n",
        "\n",
        "# Define the RGCN layer\n",
        "rgat_input2 = GNNInput( \n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge_index,),\n",
        "    node_to_graph_map=node2graph,\n",
        "    num_graphs=num_graph, \n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "#Get the default hyperparameters for the GNN model and set the hidden dimension to 64\n",
        "params6 = GNN.get_default_hyperparameters()\n",
        "params6[\"hidden_dim\"] = 64\n",
        "#Set the number of hidden layers for the aggregation MLP to 32\n",
        "params6[\"num_aggr_MLP_HIDDEN_LAYERS\"] = 32\n",
        "#Set the message calculation class to RGAT (Relational Graph Attention Network)\n",
        "params6['message_calculation_class']= 'RGAT'\n",
        "#Set the number of attention heads to 4\n",
        "params6['num_heads']= 4\n",
        "\n",
        "#Create a GNN layer with the given parameters\n",
        "rgat_layer2 = GNN(params6)\n",
        "\n",
        "#Apply the GNN layer to the input and get the output node representations\n",
        "rgat_out2 = rgat_layer2(rgat_input2)\n",
        "#Print the shape and values of rgat_out2\n",
        "print('rgan_out', rgat_out2)\n",
        "\n",
        "#Compute the mean of the node representations for each graph using segment_mean\n",
        "avg = segment_mean(\n",
        "    data=rgat_out2,\n",
        "    segment_ids=node2graph\n",
        ")\n",
        "#Print the shape and values of avg\n",
        "print('mean:', avg)\n",
        "\n",
        "#Apply a dense layer with sigmoid activation to get the prediction for each graph\n",
        "pred6 = Dense(1, activation='sigmoid')(avg)\n",
        "print('pred:', pred6)\n",
        "\n",
        "#Define the model with inputs and outputs\n",
        "model6 = Model(\n",
        "    inputs={\n",
        "        'data': data,\n",
        "        'edges': edge_index,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs=pred6\n",
        ")\n",
        "model6.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSKg1bdZm1Ag"
      },
      "outputs": [],
      "source": [
        "#Set up the model for binary classification with BinaryCrossentropy loss and AUC metric\n",
        "model6.compile(\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b80b3d3-76f1-4703-f519-fe967a745b77",
        "id": "B_ZvgkmOm1Ag"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "728/728 [==============================] - 41s 46ms/step - loss: 0.6635 - auc: 0.6397 - val_loss: 0.6245 - val_auc: 0.7095\n",
            "Epoch 2/30\n",
            "728/728 [==============================] - 20s 28ms/step - loss: 0.6107 - auc: 0.7272 - val_loss: 0.6208 - val_auc: 0.7402\n",
            "Epoch 3/30\n",
            "728/728 [==============================] - 21s 29ms/step - loss: 0.5869 - auc: 0.7563 - val_loss: 0.5912 - val_auc: 0.7559\n",
            "Epoch 4/30\n",
            "728/728 [==============================] - 20s 28ms/step - loss: 0.5789 - auc: 0.7645 - val_loss: 0.5828 - val_auc: 0.7661\n",
            "Epoch 5/30\n",
            "728/728 [==============================] - 21s 29ms/step - loss: 0.5675 - auc: 0.7771 - val_loss: 0.5748 - val_auc: 0.7762\n",
            "Epoch 6/30\n",
            "728/728 [==============================] - 20s 28ms/step - loss: 0.5664 - auc: 0.7803 - val_loss: 0.5655 - val_auc: 0.7901\n",
            "Epoch 7/30\n",
            "728/728 [==============================] - 27s 37ms/step - loss: 0.5543 - auc: 0.7925 - val_loss: 0.5471 - val_auc: 0.8037\n",
            "Epoch 8/30\n",
            "728/728 [==============================] - 23s 32ms/step - loss: 0.5423 - auc: 0.8010 - val_loss: 0.5401 - val_auc: 0.8121\n",
            "Epoch 9/30\n",
            "728/728 [==============================] - 22s 30ms/step - loss: 0.5252 - auc: 0.8168 - val_loss: 0.5154 - val_auc: 0.8304\n",
            "Epoch 10/30\n",
            "728/728 [==============================] - 21s 28ms/step - loss: 0.5108 - auc: 0.8281 - val_loss: 0.4972 - val_auc: 0.8407\n",
            "Epoch 11/30\n",
            "728/728 [==============================] - 28s 39ms/step - loss: 0.4993 - auc: 0.8367 - val_loss: 0.4962 - val_auc: 0.8462\n",
            "Epoch 12/30\n",
            "728/728 [==============================] - 29s 40ms/step - loss: 0.4877 - auc: 0.8460 - val_loss: 0.4834 - val_auc: 0.8497\n",
            "Epoch 13/30\n",
            "728/728 [==============================] - 28s 38ms/step - loss: 0.4732 - auc: 0.8565 - val_loss: 0.4569 - val_auc: 0.8682\n",
            "Epoch 14/30\n",
            "728/728 [==============================] - 28s 38ms/step - loss: 0.4596 - auc: 0.8655 - val_loss: 0.4544 - val_auc: 0.8726\n",
            "Epoch 15/30\n",
            "728/728 [==============================] - 32s 44ms/step - loss: 0.4418 - auc: 0.8770 - val_loss: 0.4288 - val_auc: 0.8868\n",
            "Epoch 16/30\n",
            "728/728 [==============================] - 29s 39ms/step - loss: 0.4286 - auc: 0.8844 - val_loss: 0.4115 - val_auc: 0.8974\n",
            "Epoch 17/30\n",
            "728/728 [==============================] - 29s 40ms/step - loss: 0.4132 - auc: 0.8932 - val_loss: 0.4192 - val_auc: 0.8956\n",
            "Epoch 18/30\n",
            "728/728 [==============================] - 28s 39ms/step - loss: 0.4026 - auc: 0.8994 - val_loss: 0.3786 - val_auc: 0.9132\n",
            "Epoch 19/30\n",
            "728/728 [==============================] - 32s 44ms/step - loss: 0.3878 - auc: 0.9073 - val_loss: 0.3758 - val_auc: 0.9132\n",
            "Epoch 20/30\n",
            "728/728 [==============================] - 26s 35ms/step - loss: 0.3765 - auc: 0.9127 - val_loss: 0.3664 - val_auc: 0.9188\n",
            "Epoch 21/30\n",
            "728/728 [==============================] - 20s 27ms/step - loss: 0.3650 - auc: 0.9181 - val_loss: 0.3508 - val_auc: 0.9241\n",
            "Epoch 22/30\n",
            "728/728 [==============================] - 21s 29ms/step - loss: 0.3606 - auc: 0.9201 - val_loss: 0.3410 - val_auc: 0.9293\n",
            "Epoch 23/30\n",
            "728/728 [==============================] - 20s 27ms/step - loss: 0.3502 - auc: 0.9251 - val_loss: 0.3437 - val_auc: 0.9317\n",
            "Epoch 24/30\n",
            "728/728 [==============================] - 21s 29ms/step - loss: 0.3394 - auc: 0.9292 - val_loss: 0.3280 - val_auc: 0.9358\n",
            "Epoch 25/30\n",
            "728/728 [==============================] - 21s 28ms/step - loss: 0.3326 - auc: 0.9323 - val_loss: 0.3268 - val_auc: 0.9343\n",
            "Epoch 26/30\n",
            "728/728 [==============================] - 20s 27ms/step - loss: 0.3266 - auc: 0.9350 - val_loss: 0.3050 - val_auc: 0.9431\n",
            "Epoch 27/30\n",
            "728/728 [==============================] - 21s 28ms/step - loss: 0.3199 - auc: 0.9373 - val_loss: 0.3167 - val_auc: 0.9467\n",
            "Epoch 28/30\n",
            "728/728 [==============================] - 20s 27ms/step - loss: 0.3111 - auc: 0.9403 - val_loss: 0.2906 - val_auc: 0.9497\n",
            "Epoch 29/30\n",
            "728/728 [==============================] - 21s 29ms/step - loss: 0.3090 - auc: 0.9414 - val_loss: 0.2983 - val_auc: 0.9454\n",
            "Epoch 30/30\n",
            "728/728 [==============================] - 21s 29ms/step - loss: 0.2960 - auc: 0.9460 - val_loss: 0.2864 - val_auc: 0.9495\n"
          ]
        }
      ],
      "source": [
        "#Train the model for 30 epochs using a custom data generator and batch size of 32\n",
        "\n",
        "import math\n",
        "\n",
        "batch_size = 32\n",
        "num_batchs = math.ceil(len(x) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(y) / batch_size)\n",
        "\n",
        "history = model6.fit(\n",
        "    gen_batch(\n",
        "        x, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=30,\n",
        "    validation_data=gen_batch(\n",
        "        y, batch_size=32, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3e74dc9-d97c-4fd5-851d-c1f83474373b",
        "id": "PGktRCXom1Ag"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "386/386 [==============================] - 3s 7ms/step\n"
          ]
        }
      ],
      "source": [
        "# Use the model to make predictions on the test data\n",
        "# The test data is generated in batches of 32 and not shuffled\n",
        "y_pred6 = model6.predict(\n",
        "    gen_batch(test, batch_size=32, shuffle=False)\n",
        ")\n",
        "# Reshape the predictions to a one-dimensional array\n",
        "y_pred6 = np.reshape(y_pred6, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df9bdc69-05ce-469a-f60a-dd27f733ff29",
        "id": "s0nOhThrm1Ag"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12326"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "len(y_pred6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RL8ZjRonm1Ag"
      },
      "outputs": [],
      "source": [
        "#  (if for kaggle competition and it is about genre prediction)\n",
        "import pandas as pd \n",
        "submission = pd.DataFrame({'label':y_pred6})\n",
        "submission.index.name = 'id'\n",
        "submission.to_csv('sample_submission6.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This trail get Score: 0.8141 on kaggle.\n"
      ],
      "metadata": {
        "id": "rq8G6p20okcL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`it's better than the previous RGAT trail before UP sampling and there is no overfitting or underfitting.`\n",
        "I think we can get a better score if we change the number of epochs and batch size."
      ],
      "metadata": {
        "id": "3ayKaKBsxi8z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Eighth Trail\n",
        "#RGCN after resampling\n",
        "\n",
        "RGCN, or Relational Graph Convolution Network , is a type of Graph Neural Network (GNN) that can be used for modeling relational data. Specifically, RGCNs can be used for link prediction and recommendation systems, where the goal is to predict the presence or absence of a connection between two entities in a graph.\n",
        "\n",
        "may require experimentation and testing to determine the most effective approach. \n",
        "\n",
        "RGCNs can be used to predict the efficacy of potential drugs based on their molecular structures and relationships with biological targets. By analyzing the graph structure of the relationship network between drugs, molecular structures, and biological targets, RGCNs can learn to extract features that are important in predicting the anti-cancer activity of compounds.\n",
        "\n",
        "RGCNs can provide a powerful tool for anti-cancer activity prediction by leveraging the structure of relational data and identifying key features and relationships that are important in predicting cancer outcomes, an RGCN model could be a suitable choice\n"
      ],
      "metadata": {
        "id": "d2m8Mub9pGYQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`I expect the performance will be better than the previous RGCN trail before Up sampling.`\n"
      ],
      "metadata": {
        "id": "BtM7q1_8yrBL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "681a9cde-a151-4546-cdd4-9e4876c0327c",
        "id": "YrCyQPJlpGYT"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rgcn_out KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='gnn_4/StatefulPartitionedCall:0', description=\"created by layer 'gnn_4'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='tf.math.segment_mean_4/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_4'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_4/Sigmoid:0', description=\"created by layer 'dense_4'\")\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_15 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_13 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_4 (TFOpLamb  ()                  0           ['input_15[0][0]']               \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_4 (Embedding)        (None, 20)           10000       ['input_13[0][0]']               \n",
            "                                                                                                  \n",
            " input_14 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_4 (TFOpLa  ()                  0           ['tf.math.reduce_max_4[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_4 (GNN)                    (None, 64)           71552       ['embedding_4[0][0]',            \n",
            "                                                                  'input_14[0][0]',               \n",
            "                                                                  'input_15[0][0]',               \n",
            "                                                                  'tf.__operators__.add_4[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_4 (TFOpLa  (None, 64)          0           ['gnn_4[0][0]',                  \n",
            " mbda)                                                            'input_15[0][0]']               \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 1)            65          ['tf.math.segment_mean_4[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 81,617\n",
            "Trainable params: 81,617\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Import the necessary modules\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, Lambda\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "#Define the input for the node features (a batch of sequences of tokens)\n",
        "data = Input(batch_shape=(None,))\n",
        "\n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "edge_index = Input(batch_shape=(None, 2),  dtype=tf.int32)\n",
        "node2graph = Input(batch_shape=(None,), dtype=tf.int32)\n",
        "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
        "\n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1\n",
        "\n",
        "# Define the RGCN layer\n",
        "rgcn_input2 = GNNInput( \n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge_index,),\n",
        "    node_to_graph_map=node2graph,\n",
        "    num_graphs=num_graph, \n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "#Get the default hyperparameters for the GNN model and set the hidden dimension to 64\n",
        "params7 = GNN.get_default_hyperparameters()\n",
        "params7[\"hidden_dim\"] = 64\n",
        "#Set the number of hidden layers for the aggregation MLP to 32\n",
        "params7[\"num_aggr_MLP_HIDDEN_LAYERS\"] = 32\n",
        "#Set the message calculation class to RGCN (Relational Graph Convolutional Network)\n",
        "params7['message_calculation_class']= 'RGCN'\n",
        "#Create a GNN layer with the given parameters\n",
        "rgcn_layer2 = GNN(params7)\n",
        "\n",
        "#Apply the GNN layer to the input and get the output node representations\n",
        "rgcn_out2 = rgcn_layer2(rgcn_input2)\n",
        "\n",
        "#Print the shape and values of rgcn_out2\n",
        "print('rgcn_out', rgcn_out2)\n",
        "\n",
        "#Compute the mean of the node representations for each graph using segment_mean\n",
        "avg = segment_mean(\n",
        "    data=rgcn_out2,\n",
        "    segment_ids=node2graph\n",
        ")\n",
        "\n",
        "#Print the shape and values of avg\n",
        "print('mean:', avg)\n",
        "\n",
        "#Apply a dense layer with sigmoid activation to get the prediction for each graph\n",
        "pred7 = Dense(1, activation='sigmoid')(avg)\n",
        "print('pred:', pred7)\n",
        "\n",
        "#Define the model with inputs and outputs\n",
        "model7 = Model(\n",
        "    inputs={\n",
        "        'data': data,\n",
        "        'edges': edge_index,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs=pred7\n",
        ")\n",
        "model7.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJ40E7s1pGYW"
      },
      "outputs": [],
      "source": [
        "#Set up the model for binary classification with BinaryCrossentropy loss and AUC metric\n",
        "model7.compile(\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d465402a-e6f6-4544-c79b-6f4a7d1f8136",
        "id": "x_Q2-SbxpGYX"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "728/728 [==============================] - 16s 17ms/step - loss: 0.6591 - auc: 0.6459 - val_loss: 0.6262 - val_auc: 0.7122\n",
            "Epoch 2/20\n",
            "728/728 [==============================] - 12s 16ms/step - loss: 0.6063 - auc: 0.7322 - val_loss: 0.6013 - val_auc: 0.7444\n",
            "Epoch 3/20\n",
            "728/728 [==============================] - 12s 16ms/step - loss: 0.5903 - auc: 0.7509 - val_loss: 0.5897 - val_auc: 0.7559\n",
            "Epoch 4/20\n",
            "728/728 [==============================] - 13s 18ms/step - loss: 0.5845 - auc: 0.7569 - val_loss: 0.6004 - val_auc: 0.7531\n",
            "Epoch 5/20\n",
            "728/728 [==============================] - 11s 15ms/step - loss: 0.5782 - auc: 0.7637 - val_loss: 0.5861 - val_auc: 0.7636\n",
            "Epoch 6/20\n",
            "728/728 [==============================] - 12s 16ms/step - loss: 0.5694 - auc: 0.7718 - val_loss: 0.5804 - val_auc: 0.7764\n",
            "Epoch 7/20\n",
            "728/728 [==============================] - 11s 15ms/step - loss: 0.5643 - auc: 0.7796 - val_loss: 0.5649 - val_auc: 0.7821\n",
            "Epoch 8/20\n",
            "728/728 [==============================] - 10s 14ms/step - loss: 0.5586 - auc: 0.7847 - val_loss: 0.5574 - val_auc: 0.7866\n",
            "Epoch 9/20\n",
            "728/728 [==============================] - 12s 17ms/step - loss: 0.5572 - auc: 0.7861 - val_loss: 0.5648 - val_auc: 0.7833\n",
            "Epoch 10/20\n",
            "728/728 [==============================] - 13s 17ms/step - loss: 0.5469 - auc: 0.7958 - val_loss: 0.5578 - val_auc: 0.7914\n",
            "Epoch 11/20\n",
            "728/728 [==============================] - 12s 17ms/step - loss: 0.5430 - auc: 0.8003 - val_loss: 0.5490 - val_auc: 0.8015\n",
            "Epoch 12/20\n",
            "728/728 [==============================] - 11s 15ms/step - loss: 0.5365 - auc: 0.8068 - val_loss: 0.5528 - val_auc: 0.7947\n",
            "Epoch 13/20\n",
            "728/728 [==============================] - 11s 15ms/step - loss: 0.5278 - auc: 0.8141 - val_loss: 0.5341 - val_auc: 0.8108\n",
            "Epoch 14/20\n",
            "728/728 [==============================] - 15s 20ms/step - loss: 0.5205 - auc: 0.8213 - val_loss: 0.5240 - val_auc: 0.8223\n",
            "Epoch 15/20\n",
            "728/728 [==============================] - 13s 18ms/step - loss: 0.5135 - auc: 0.8270 - val_loss: 0.5224 - val_auc: 0.8274\n",
            "Epoch 16/20\n",
            "728/728 [==============================] - 13s 17ms/step - loss: 0.5062 - auc: 0.8327 - val_loss: 0.5269 - val_auc: 0.8306\n",
            "Epoch 17/20\n",
            "728/728 [==============================] - 15s 21ms/step - loss: 0.4974 - auc: 0.8399 - val_loss: 0.5059 - val_auc: 0.8392\n",
            "Epoch 18/20\n",
            "728/728 [==============================] - 14s 19ms/step - loss: 0.4900 - auc: 0.8458 - val_loss: 0.4895 - val_auc: 0.8485\n",
            "Epoch 19/20\n",
            "728/728 [==============================] - 19s 26ms/step - loss: 0.4802 - auc: 0.8536 - val_loss: 0.4755 - val_auc: 0.8579\n",
            "Epoch 20/20\n",
            "728/728 [==============================] - 13s 18ms/step - loss: 0.4738 - auc: 0.8581 - val_loss: 0.4812 - val_auc: 0.8541\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efdb04f3af0>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "#Train the model for 20 epochs using a custom data generator and batch size of 32\n",
        "\n",
        "import math\n",
        "\n",
        "batch_size = 32\n",
        "num_batchs = math.ceil(len(x) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(y) / batch_size)\n",
        "\n",
        "model7.fit(\n",
        "    gen_batch(\n",
        "        x, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=20,\n",
        "    validation_data=gen_batch(\n",
        "        y, batch_size=32, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bc5b908-3868-470a-87fe-f0709b034f87",
        "id": "XX81LYxwpGYY"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "386/386 [==============================] - 2s 5ms/step\n"
          ]
        }
      ],
      "source": [
        "# Use the model to make predictions on the test data\n",
        "# The test data is generated in batches of 32 and not shuffled\n",
        "y_pred7 = model7.predict(\n",
        "    gen_batch(test, batch_size=32, shuffle=False)\n",
        ")\n",
        "# Reshape the predictions to a one-dimensional array\n",
        "y_pred7 = np.reshape(y_pred7, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78e12f3f-7625-4816-ccd3-0db6ed10342a",
        "id": "YySPm39dpGYZ"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12326"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "len(y_pred7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71eE17q4pGYa"
      },
      "outputs": [],
      "source": [
        "#  (if for kaggle competition and it is about genre prediction)\n",
        "import pandas as pd \n",
        "submission = pd.DataFrame({'label':y_pred7})\n",
        "submission.index.name = 'id'\n",
        "submission.to_csv('sample_submission7.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This trail get score Score: 0.79093 on Kaggle "
      ],
      "metadata": {
        "id": "QCp5hUbkpGYa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`it's better than the previous RGCN trail before UP sampling and there is no overfitting or underfitting.`"
      ],
      "metadata": {
        "id": "0RH6lHR5zJuo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The Ninth trail\n",
        "#RGIN after resampling\n",
        "\n",
        "* a Relational Graph Isomorphism Network (RGIN) is a type of Graph Neural Network (GNN) that has a high discriminative power and can capture complex structural patterns in graphs. It is based on the idea of the Weisfeiler-Lehman test, which is a method to check if two graphs are isomorphic, i.e., have the same structure. A RGIN uses a simple aggregator function that updates the node features by adding the sum of the neighbor features and applying a nonlinear transformation. This way, it can preserve the node identity and distinguish between different graph structures. This way, it can preserve the node identity and distinguish between different graph structures.\n",
        "* We set the message calculation class to RGIN when we want to use this powerful GNN architecture for graph representation learning tasks, such as node classification, graph classification, or link prediction. RGIN can learn more expressive and informative node embeddings than other GNN models, such as GCN or GraphSAGE, which use more complex aggregators that may lose some structural information. RGIN can also handle graphs with different types of edges or relations, by using different weight matrices for each edge type.\n",
        "* RGIN can learn the structural and relational features of ACPs and their interactions with cancer cell membranes, and predict their anti-cancer activity based on their node embeddings. RGIN can also provide interpretable explanations for the predictions by highlighting the important nodes and edges that contribute to the anti-cancer activity of ACPs. \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0zDIHeLGr2eL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`I don't think it will get much better but let's try`\n"
      ],
      "metadata": {
        "id": "3t5n1MtVjXqR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f98059a-f492-4411-e5e6-8a05c64dcd6d",
        "id": "2Zd-PZ5wr2eM"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rgin_out KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='gnn_6/StatefulPartitionedCall:0', description=\"created by layer 'gnn_6'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='tf.math.segment_mean_5/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_5'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_5/Sigmoid:0', description=\"created by layer 'dense_5'\")\n",
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_21 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_19 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_6 (TFOpLamb  ()                  0           ['input_21[0][0]']               \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_6 (Embedding)        (None, 20)           10000       ['input_19[0][0]']               \n",
            "                                                                                                  \n",
            " input_20 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_6 (TFOpLa  ()                  0           ['tf.math.reduce_max_6[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_6 (GNN)                    (None, 64)           1136512     ['embedding_6[0][0]',            \n",
            "                                                                  'input_20[0][0]',               \n",
            "                                                                  'input_21[0][0]',               \n",
            "                                                                  'tf.__operators__.add_6[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_5 (TFOpLa  (None, 64)          0           ['gnn_6[0][0]',                  \n",
            " mbda)                                                            'input_21[0][0]']               \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 1)            65          ['tf.math.segment_mean_5[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,146,577\n",
            "Trainable params: 1,146,577\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Define the input for the node features (a batch of sequences of tokens)\n",
        "data = Input(batch_shape=(None,))\n",
        "\n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "edge_index = Input(batch_shape=(None, 2),  dtype=tf.int32)\n",
        "node2graph = Input(batch_shape=(None,), dtype=tf.int32)\n",
        "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
        "\n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1\n",
        "\n",
        "# Define the RGIN layer\n",
        "rgin_input2 = GNNInput( \n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge_index,),\n",
        "    node_to_graph_map=node2graph,\n",
        "    num_graphs=num_graph, \n",
        ")\n",
        "#Get the default hyperparameters for the GNN model and set the hidden dimension to 64\n",
        "params8 = GNN.get_default_hyperparameters()\n",
        "params8[\"hidden_dim\"] = 64\n",
        "#Set the number of hidden layers for the aggregation MLP to 64\n",
        "params8[\"num_aggr_MLP_hidden_layers\"] = 64\n",
        "#Set the message calculation class to RGIN (Relational Graph Isomorphism Network)\n",
        "params8['message_calculation_class']= 'RGIN'\n",
        "\n",
        "#Create a GNN layer with the given parameters\n",
        "rgin_layer2 = GNN(params8)\n",
        "\n",
        "#Apply the GNN layer to the input and get the output node representations\n",
        "rgin_out2 = rgin_layer2(rgin_input2)\n",
        "\n",
        "#Print the shape and values of rgin_out2\n",
        "print('rgin_out', rgin_out2)\n",
        "\n",
        "#Compute the mean of the node representations for each graph using segment_mean\n",
        "avg = segment_mean(\n",
        "    data=rgin_out2,\n",
        "    segment_ids=node2graph\n",
        ")\n",
        "\n",
        "#Print the shape and values of avg\n",
        "print('mean:', avg)\n",
        "\n",
        "#Apply a dense layer with sigmoid activation to get the prediction for each graph\n",
        "pred8 = Dense(1, activation='sigmoid')(avg)\n",
        "print('pred:', pred8)\n",
        "\n",
        "#Define the model with inputs and outputs\n",
        "model8 = Model(\n",
        "    inputs={\n",
        "        'data': data,\n",
        "        'edges': edge_index,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs=pred8\n",
        ")\n",
        "model8.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUH9P5_Rr2eN"
      },
      "outputs": [],
      "source": [
        "#Set up the model for binary classification with BinaryCrossentropy loss and AUC metric\n",
        "model8.compile(\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ec2bff6-a0f0-480e-91f1-483a1ad53aa1",
        "id": "WcWvPxJkr2eN"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "728/728 [==============================] - 102s 66ms/step - loss: 0.6932 - auc: 0.4960 - val_loss: 0.6932 - val_auc: 0.5000\n",
            "Epoch 2/30\n",
            "728/728 [==============================] - 46s 64ms/step - loss: 0.6932 - auc: 0.4956 - val_loss: 0.6931 - val_auc: 0.5000\n",
            "Epoch 3/30\n",
            "728/728 [==============================] - 50s 68ms/step - loss: 0.6932 - auc: 0.4985 - val_loss: 0.6932 - val_auc: 0.5000\n",
            "Epoch 4/30\n",
            "728/728 [==============================] - 59s 81ms/step - loss: 0.6932 - auc: 0.4964 - val_loss: 0.6932 - val_auc: 0.5000\n",
            "Epoch 5/30\n",
            "728/728 [==============================] - 62s 84ms/step - loss: 0.6932 - auc: 0.4972 - val_loss: 0.6932 - val_auc: 0.5000\n",
            "Epoch 6/30\n",
            "728/728 [==============================] - 56s 77ms/step - loss: 0.6932 - auc: 0.4984 - val_loss: 0.6931 - val_auc: 0.5000\n",
            "Epoch 7/30\n",
            "728/728 [==============================] - 59s 81ms/step - loss: 0.6932 - auc: 0.4951 - val_loss: 0.6931 - val_auc: 0.5000\n",
            "Epoch 8/30\n",
            "728/728 [==============================] - 42s 58ms/step - loss: 0.6932 - auc: 0.4990 - val_loss: 0.6931 - val_auc: 0.5000\n",
            "Epoch 9/30\n",
            "728/728 [==============================] - 42s 57ms/step - loss: 0.6932 - auc: 0.4970 - val_loss: 0.6932 - val_auc: 0.5000\n",
            "Epoch 10/30\n",
            "728/728 [==============================] - 43s 59ms/step - loss: 0.6932 - auc: 0.4985 - val_loss: 0.6931 - val_auc: 0.5000\n",
            "Epoch 11/30\n",
            "728/728 [==============================] - 42s 58ms/step - loss: 0.6932 - auc: 0.4954 - val_loss: 0.6931 - val_auc: 0.5000\n",
            "Epoch 12/30\n",
            "728/728 [==============================] - 43s 59ms/step - loss: 0.6932 - auc: 0.4980 - val_loss: 0.6932 - val_auc: 0.5000\n",
            "Epoch 13/30\n",
            "728/728 [==============================] - 42s 58ms/step - loss: 0.6932 - auc: 0.4982 - val_loss: 0.6932 - val_auc: 0.5000\n",
            "Epoch 14/30\n",
            "728/728 [==============================] - 42s 58ms/step - loss: 0.6932 - auc: 0.4999 - val_loss: 0.6932 - val_auc: 0.5000\n",
            "Epoch 15/30\n",
            "728/728 [==============================] - 42s 57ms/step - loss: 0.6932 - auc: 0.4998 - val_loss: 0.6933 - val_auc: 0.5000\n",
            "Epoch 16/30\n",
            "728/728 [==============================] - 41s 57ms/step - loss: 0.6932 - auc: 0.4935 - val_loss: 0.6932 - val_auc: 0.5000\n",
            "Epoch 17/30\n",
            "728/728 [==============================] - 42s 58ms/step - loss: 0.6932 - auc: 0.4994 - val_loss: 0.6932 - val_auc: 0.5000\n",
            "Epoch 18/30\n",
            "728/728 [==============================] - 41s 57ms/step - loss: 0.6932 - auc: 0.4933 - val_loss: 0.6932 - val_auc: 0.5000\n",
            "Epoch 19/30\n",
            "728/728 [==============================] - 41s 57ms/step - loss: 0.6932 - auc: 0.4987 - val_loss: 0.6932 - val_auc: 0.5000\n",
            "Epoch 20/30\n",
            "728/728 [==============================] - 42s 57ms/step - loss: 0.6932 - auc: 0.5006 - val_loss: 0.6933 - val_auc: 0.5000\n",
            "Epoch 21/30\n",
            "728/728 [==============================] - 42s 57ms/step - loss: 0.6932 - auc: 0.4978 - val_loss: 0.6932 - val_auc: 0.5000\n",
            "Epoch 22/30\n",
            "728/728 [==============================] - 41s 57ms/step - loss: 0.6932 - auc: 0.4977 - val_loss: 0.6932 - val_auc: 0.5000\n",
            "Epoch 23/30\n",
            "728/728 [==============================] - 40s 56ms/step - loss: 0.6932 - auc: 0.4973 - val_loss: 0.6931 - val_auc: 0.5000\n",
            "Epoch 24/30\n",
            "728/728 [==============================] - 42s 58ms/step - loss: 0.6932 - auc: 0.4997 - val_loss: 0.6932 - val_auc: 0.5000\n",
            "Epoch 25/30\n",
            "728/728 [==============================] - 43s 59ms/step - loss: 0.6932 - auc: 0.4986 - val_loss: 0.6932 - val_auc: 0.5000\n",
            "Epoch 26/30\n",
            "728/728 [==============================] - 41s 56ms/step - loss: 0.6931 - auc: 0.5029 - val_loss: 0.6932 - val_auc: 0.5000\n",
            "Epoch 27/30\n",
            "728/728 [==============================] - 40s 56ms/step - loss: 0.6932 - auc: 0.4989 - val_loss: 0.6932 - val_auc: 0.5000\n",
            "Epoch 28/30\n",
            "728/728 [==============================] - 41s 57ms/step - loss: 0.6932 - auc: 0.4974 - val_loss: 0.6931 - val_auc: 0.5000\n",
            "Epoch 29/30\n",
            "728/728 [==============================] - 41s 57ms/step - loss: 0.6932 - auc: 0.5011 - val_loss: 0.6933 - val_auc: 0.5000\n",
            "Epoch 30/30\n",
            "728/728 [==============================] - 41s 56ms/step - loss: 0.6932 - auc: 0.4964 - val_loss: 0.6932 - val_auc: 0.5000\n"
          ]
        }
      ],
      "source": [
        "#Train the model for 30 epochs using a custom data generator and batch size of 32\n",
        "\n",
        "import math\n",
        "\n",
        "batch_size = 32\n",
        "num_batchs = math.ceil(len(x) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(y) / batch_size)\n",
        "\n",
        "history = model8.fit(\n",
        "    gen_batch(\n",
        "        x, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=30,\n",
        "    validation_data=gen_batch(\n",
        "        y, batch_size=32, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e66f170-2360-4d31-f6fc-61857055bbe5",
        "id": "JLg83nrHr2eO"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "386/386 [==============================] - 6s 13ms/step\n"
          ]
        }
      ],
      "source": [
        "# Use the model to make predictions on the test data\n",
        "# The test data is generated in batches of 32 and not shuffled\n",
        "y_pred8 = model8.predict(\n",
        "    gen_batch(test, batch_size=32, shuffle=False)\n",
        ")\n",
        "# Reshape the predictions to a one-dimensional array\n",
        "y_pred8 = np.reshape(y_pred8, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d200d55c-bbc9-4c71-e408-b3ae47b2a20b",
        "id": "gWoVgyXZr2eO"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12326"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "len(y_pred8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18465GNJr2eO"
      },
      "outputs": [],
      "source": [
        "#  (if for kaggle competition and it is about genre prediction)\n",
        "import pandas as pd \n",
        "submission = pd.DataFrame({'label':y_pred8})\n",
        "submission.index.name = 'id'\n",
        "submission.to_csv('sample_submission8.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This trail get score 0.5 on Kaggle "
      ],
      "metadata": {
        "id": "i2_7G-ktr2eP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`As I expected,it's still the worst trail, this confirms that RGIN is not effective with this data`\n"
      ],
      "metadata": {
        "id": "ITXXZ8OH0Fp9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Tenth Trail\n",
        "#GNN after resampling\n",
        "GNNs are particularly useful in scenarios where the data is structured as a graph, which consists of nodes and edges that connect them. GNNs can learn to effectively capture information from the graph structure, such as local and global relationships between nodes, and use this information to make predictions or perform other tasks.\n",
        "\n"
      ],
      "metadata": {
        "id": "TsnrcJovtnfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GNNs can be a powerful tool for anti-cancer activity prediction, leveraging the structure of molecular and drug interaction networks to identify potential therapeutics.\n",
        "we will check that:\n",
        "\n"
      ],
      "metadata": {
        "id": "BBfCRPCPtnfb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`I expect the performance will be better than the previous GNN trail.`\n"
      ],
      "metadata": {
        "id": "fb407Mp-0rPt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "466771ec-1e83-4e81-dffb-07a0570c8416",
        "id": "_GlZszsgtnfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 16), dtype=tf.float32, name=None), name='gnn_7/StatefulPartitionedCall:0', description=\"created by layer 'gnn_7'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 16), dtype=tf.float32, name=None), name='tf.math.segment_mean_6/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_6'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_6/Sigmoid:0', description=\"created by layer 'dense_6'\")\n",
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_24 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_22 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_7 (TFOpLamb  ()                  0           ['input_24[0][0]']               \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_7 (Embedding)        (None, 20)           10000       ['input_22[0][0]']               \n",
            "                                                                                                  \n",
            " input_23 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_7 (TFOpLa  ()                  0           ['tf.math.reduce_max_7[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_7 (GNN)                    (None, 16)           7904        ['embedding_7[0][0]',            \n",
            "                                                                  'input_23[0][0]',               \n",
            "                                                                  'input_24[0][0]',               \n",
            "                                                                  'tf.__operators__.add_7[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_6 (TFOpLa  (None, 16)          0           ['gnn_7[0][0]',                  \n",
            " mbda)                                                            'input_24[0][0]']               \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 1)            17          ['tf.math.segment_mean_6[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 17,921\n",
            "Trainable params: 17,921\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Define the input for the node features (a batch of sequences of tokens)\n",
        "data = keras.Input(batch_shape=(None,))\n",
        "\n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
        "\n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1\n",
        "# Define the GNN layer\n",
        "gnn_input2 = GNNInput(\n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge,),\n",
        "    node_to_graph_map=node2graph, \n",
        "    num_graphs=num_graph,\n",
        ")\n",
        "\n",
        "#Get the default hyperparameters for the GNN model and set the hidden dimension to 16\n",
        "params9 = GNN.get_default_hyperparameters()\n",
        "params9[\"hidden_dim\"] = 16\n",
        "\n",
        "#Create a GNN layer with the given parameters\n",
        "gnn_layer2 = GNN(params9)\n",
        "#Apply the GNN layer to the input and get the output node representations\n",
        "gnn_out2 = gnn_layer2(gnn_input2)\n",
        "\n",
        "#Print the shape and values of gnn_out2\n",
        "print('gnn_out', gnn_out2)\n",
        "\n",
        "#Compute the mean of the node representations for each graph using segment_mean\n",
        "avg = segment_mean(\n",
        "    data=gnn_out2,\n",
        "    segment_ids=node2graph\n",
        ")\n",
        "\n",
        "#Print the shape and values of avg\n",
        "print('mean:', avg)\n",
        "\n",
        "#Apply a dense layer with sigmoid activation to get the prediction for each graph\n",
        "pred9 = Dense(1, activation='sigmoid')(avg)\n",
        "print('pred:', pred9)\n",
        "\n",
        "#Define the model with inputs and outputs\n",
        "model9 = Model(\n",
        "    inputs={\n",
        "        'data': data,\n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs=pred9\n",
        ")\n",
        "model9.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XzbBAX6Gtnfc"
      },
      "outputs": [],
      "source": [
        "#Set up the model for binary classification with BinaryCrossentropy loss and AUC metric\n",
        "model9.compile(\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "610329c7-7d67-4abd-d20b-24cf8dcb43eb",
        "id": "UQKuDRbjtnfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "728/728 [==============================] - 17s 18ms/step - loss: 0.6796 - auc: 0.6045 - val_loss: 0.6637 - val_auc: 0.6389\n",
            "Epoch 2/15\n",
            "728/728 [==============================] - 11s 16ms/step - loss: 0.6366 - auc: 0.6837 - val_loss: 0.6168 - val_auc: 0.7153\n",
            "Epoch 3/15\n",
            "728/728 [==============================] - 12s 16ms/step - loss: 0.6074 - auc: 0.7275 - val_loss: 0.6035 - val_auc: 0.7419\n",
            "Epoch 4/15\n",
            "728/728 [==============================] - 11s 16ms/step - loss: 0.5977 - auc: 0.7411 - val_loss: 0.6008 - val_auc: 0.7456\n",
            "Epoch 5/15\n",
            "728/728 [==============================] - 11s 16ms/step - loss: 0.5911 - auc: 0.7477 - val_loss: 0.5955 - val_auc: 0.7502\n",
            "Epoch 6/15\n",
            "728/728 [==============================] - 12s 16ms/step - loss: 0.5877 - auc: 0.7522 - val_loss: 0.5904 - val_auc: 0.7586\n",
            "Epoch 7/15\n",
            "728/728 [==============================] - 11s 15ms/step - loss: 0.5837 - auc: 0.7589 - val_loss: 0.5911 - val_auc: 0.7579\n",
            "Epoch 8/15\n",
            "728/728 [==============================] - 10s 13ms/step - loss: 0.5818 - auc: 0.7618 - val_loss: 0.5789 - val_auc: 0.7689\n",
            "Epoch 9/15\n",
            "728/728 [==============================] - 11s 16ms/step - loss: 0.5776 - auc: 0.7668 - val_loss: 0.5817 - val_auc: 0.7647\n",
            "Epoch 10/15\n",
            "728/728 [==============================] - 11s 15ms/step - loss: 0.5742 - auc: 0.7700 - val_loss: 0.5733 - val_auc: 0.7775\n",
            "Epoch 11/15\n",
            "728/728 [==============================] - 11s 15ms/step - loss: 0.5721 - auc: 0.7734 - val_loss: 0.5695 - val_auc: 0.7794\n",
            "Epoch 12/15\n",
            "728/728 [==============================] - 11s 16ms/step - loss: 0.5674 - auc: 0.7770 - val_loss: 0.5602 - val_auc: 0.7880\n",
            "Epoch 13/15\n",
            "728/728 [==============================] - 11s 16ms/step - loss: 0.5633 - auc: 0.7819 - val_loss: 0.5629 - val_auc: 0.7859\n",
            "Epoch 14/15\n",
            "728/728 [==============================] - 11s 15ms/step - loss: 0.5586 - auc: 0.7866 - val_loss: 0.5649 - val_auc: 0.7875\n",
            "Epoch 15/15\n",
            "728/728 [==============================] - 10s 14ms/step - loss: 0.5571 - auc: 0.7881 - val_loss: 0.5534 - val_auc: 0.7977\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efd91e8d2b0>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "#Train the model for 15 epochs using a custom data generator and batch size of 32\n",
        "import math\n",
        "\n",
        "batch_size = 32\n",
        "num_batchs = math.ceil(len(x) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(y) / batch_size)\n",
        "\n",
        "model9.fit(\n",
        "    gen_batch(\n",
        "        x, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=15,\n",
        "    validation_data=gen_batch(\n",
        "        y, batch_size=32, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57ff3c50-bc50-43c6-ae5b-77749e709b73",
        "id": "LgiicWQYtnfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "386/386 [==============================] - 2s 5ms/step\n"
          ]
        }
      ],
      "source": [
        "# Use the model to make predictions on the test data\n",
        "# The test data is generated in batches of 32 and not shuffled\n",
        "y_pred9 = model9.predict(\n",
        "    gen_batch(test, batch_size=32, shuffle=False)\n",
        ")\n",
        "# Reshape the predictions to a one-dimensional array\n",
        "y_pred9 = np.reshape(y_pred9, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ba5ab79-531f-4d58-a025-2e2aa3de97da",
        "id": "i9dWibY2tnfd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12326"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "len(y_pred9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0hOA7wGtnfe"
      },
      "outputs": [],
      "source": [
        "#  (if for kaggle competition and it is about genre prediction)\n",
        "import pandas as pd \n",
        "submission = pd.DataFrame({'label':y_pred9})\n",
        "submission.index.name = 'id'\n",
        "submission.to_csv('sample_submission9.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This trail get score 0.76965\n",
        " on Kaggle "
      ],
      "metadata": {
        "id": "LYrC1Rt4tnfe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`it's better than the previous GNN trail and there is no overfitting or underfitting.`"
      ],
      "metadata": {
        "id": "TYbcFVPO1Ty3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "\n",
        "\n",
        "*   UP Sampling helped improve performance, As we can see in previous trails.\n",
        "\n",
        "*   GGNN can achieve better performance and accuracy than other GNN models or traditional machine learning methods for anti-cancer activity prediction. This Trail Get Score on Kaggle (0.85219)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UlnyEHppcQb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úîÔ∏è Answer the questions"
      ],
      "metadata": {
        "id": "WiOA5ST3Ozd5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**üåàBased on the provided template, describe the format of the input file (sdf file).**\n",
        "\n",
        "*  SDF file format can be a chemical table file that describes molecules and chemical reactions. It is a text-based format that wraps the molfile format and can store multiple records delimited by four dollar signs. It is made up of a series of molfiles that have been connected together, as well as some additional information about the compounds.\n",
        "\n",
        "**üåàWhat are the input tensors to the neural network model (their meaning, not just symbol)? What is each of their dims and their meaning (e.g. batch_size)?**\n",
        "\n",
        "*  Input tensors are the data structures that represent the inputs to a neural network model. They are usually multidimensional arrays of numbers that can be manipulated by mathematical operations. They are also the primary data format used by various training frameworks such as TensorFlow and PyTorch.\n",
        "\n",
        "*  The dimensions of an input tensor depend on the type and shape of the input data. For example, if the input data is an image, the input tensor may have four dimensions: batch size, height, width, and channels. Batch size is the number of samples in a batch, height and width are the pixel dimensions of the image, and channels are the color components (such as RGB) or feature maps of the image.\n",
        "\n",
        "*  The meaning of each dimension of an input tensor also depends on the type and shape of the input data. For example, if the input data is a sequence of words, the input tensor may have three dimensions: batch size, sequence length, and vocabulary size. Batch size is the number of samples in a batch, sequence length is the number of words in a sequence, and vocabulary size is the number of unique words in the vocabulary.\n",
        "\n",
        "**üåàFor each dim of gnn_out, what does it symbolize? For each dim of avg, what does it symbolize?**\n",
        "\n",
        "*   gnn_out is a tensor of shape [num_nodes, hidden_dim], where num_nodes is the total number of nodes in all graphs, and hidden_dim is the dimension of the node representations learned by the GNN layer. Each row of gnn_out corresponds to a node in a graph, and each column corresponds to a feature of the node representation.\n",
        " \n",
        "\n",
        "*   avg is a tensor of shape [num_graphs, hidden_dim], where num_graphs is the number of graphs in the input, and hidden_dim is the same as in gnn_out. Each row of avg corresponds to a graph in the input, and each column corresponds to a feature of the graph representation. The graph representation is computed by taking the mean of the node representations for each graph using segment_mean.\n",
        "\n",
        "\n",
        "**üåàWhat is the difference between segment_mean and tf.reduce_mean? For each dim of pred, what does it symbolize?**\n",
        "\n",
        "\n",
        "*   segment_mean is a function that computes the mean of a tensor along a given dimension, but only for segments that have the same segment id.if data is a tensor of shape [6, 2] and segment_ids is a tensor of shape [6] with values [0, 0, 1, 1, 2, 2], then segment_mean(data, segment_ids) will return a tensor of shape [3, 2], where each row is the mean of two rows in data that have the same segment id. This function is useful for aggregating data by groups or categories.\n",
        "\n",
        "\n",
        "*   tf.reduce_mean is a function that computes the mean of a tensor along a given dimension or all dimensions. if data is a tensor of shape [6, 2], then tf.reduce_mean(data) will return a scalar value that is the mean of all elements in data, and tf.reduce_mean(data, axis=0) will return a tensor of shape [2] that is the mean of each column in data. This function is useful for reducing the dimensionality of data or computing global statistics.\n",
        "\n",
        "*   pred is a tensor of shape [num_graphs, num_classes], where num_graphs is the number of graphs in the input, and num_classes is the number of categories for graph classification. Each row of pred corresponds to a graph in the input, and each column corresponds to a probability score for each class. The pred tensor is computed by applying a softmax function to the output of a linear layer that takes avg as input.\n",
        "\n",
        "**üåàWhat is the motivation/theory/idea to use multiple gcn layers comparing to just one? How many layers were used in the template?**\n",
        "\n",
        "*  The motivation/theory/idea to use multiple GCN layers compared to just one is to capture the multi-hop feature aggregation of the graph data. Each GCN layer can aggregate the features of the neighboring nodes within a certain distance (or hop). By stacking multiple GCN layers, the model can learn more expressive and global features that incorporate information from nodes that are further away in the graph structure.\n",
        "\n",
        "*  there are two layers used in the template.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pFcgWagyPAXX"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ad786a4961b348379333ac9be1b6453e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5685c5357c5d43e38b46d9666527ef46",
              "IPY_MODEL_1ef2440a5fb94ecca679be6011f5c5ef",
              "IPY_MODEL_826607c0b1764e2781d1b2b9d239c1eb"
            ],
            "layout": "IPY_MODEL_7b36d147e30942c4af5b49a083f6b3f9"
          }
        },
        "5685c5357c5d43e38b46d9666527ef46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_578f7757ece7498493896320487382bc",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9844385c647e472f880b01b403324f2d",
            "value": "100%"
          }
        },
        "1ef2440a5fb94ecca679be6011f5c5ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d13d65a4ce5142a4aa83f02ea56690d7",
            "max": 25024,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a756c3f635a7446f910772109a7ed90b",
            "value": 25024
          }
        },
        "826607c0b1764e2781d1b2b9d239c1eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbc87883103e4a828d50aa34db3bafb1",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e73cc11cf337404889e22f6b53a463ae",
            "value": " 25024/25024 [00:01&lt;00:00, 14906.04it/s]"
          }
        },
        "7b36d147e30942c4af5b49a083f6b3f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "578f7757ece7498493896320487382bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9844385c647e472f880b01b403324f2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d13d65a4ce5142a4aa83f02ea56690d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a756c3f635a7446f910772109a7ed90b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bbc87883103e4a828d50aa34db3bafb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e73cc11cf337404889e22f6b53a463ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f74466b53e654495801e00571c94761b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5cc662bff3ac492eab197e2b696a9c35",
              "IPY_MODEL_8c035bd0cab84415b4a50d2a8b51a4bc",
              "IPY_MODEL_0ce446bf396344f7be24c2e9b2141c73"
            ],
            "layout": "IPY_MODEL_983bcafc04fa411f9ca92c7213d9e760"
          }
        },
        "5cc662bff3ac492eab197e2b696a9c35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1042b6361f74b7890392984c4b93cbf",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e5f88b4566544a6fa60507411aec4984",
            "value": "100%"
          }
        },
        "8c035bd0cab84415b4a50d2a8b51a4bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f88ce8c4af541b9bf86a2584c2ae6ba",
            "max": 12326,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c908b982b4954208bb5863eae59e31b8",
            "value": 12326
          }
        },
        "0ce446bf396344f7be24c2e9b2141c73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b123ae0d1ee642c0811ec0aa1be9dc71",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ed8848a79484485d96c1aa43f37d8e0d",
            "value": " 12326/12326 [00:00&lt;00:00, 14160.34it/s]"
          }
        },
        "983bcafc04fa411f9ca92c7213d9e760": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1042b6361f74b7890392984c4b93cbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5f88b4566544a6fa60507411aec4984": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f88ce8c4af541b9bf86a2584c2ae6ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c908b982b4954208bb5863eae59e31b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b123ae0d1ee642c0811ec0aa1be9dc71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed8848a79484485d96c1aa43f37d8e0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}